{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;font-size:30px;\" > Quora Question Pairs </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1. Business Problem </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1.1 Description </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Quora is a place to gain and share knowledge—about anything. It’s a platform to ask questions and connect with people who contribute unique insights and quality answers. This empowers people to learn from each other and to better understand the world.</p>\n",
    "<p>\n",
    "Over 100 million people visit Quora every month, so it's no surprise that many people ask similarly worded questions. Multiple questions with the same intent can cause seekers to spend more time finding the best answer to their question, and make writers feel they need to answer multiple versions of the same question. Quora values canonical questions because they provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\n",
    "</p>\n",
    "<br>\n",
    "> Credits: Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Problem Statement __\n",
    "- Identify which questions asked on Quora are duplicates of questions that have already been asked. \n",
    "- This could be useful to instantly provide answers to questions that have already been answered. \n",
    "- We are tasked with predicting whether a pair of questions are duplicates or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1.2 Sources/Useful Links</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Source : https://www.kaggle.com/c/quora-question-pairs\n",
    "<br><br>____ Useful Links ____\n",
    "- Discussions : https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb/comments\n",
    "- Kaggle Winning Solution and other approaches: https://www.dropbox.com/sh/93968nfnrzh8bp5/AACZdtsApc1QSTQc7X0H3QZ5a?dl=0\n",
    "- Blog 1 : https://engineering.quora.com/Semantic-Question-Matching-with-Deep-Learning\n",
    "- Blog 2 : https://towardsdatascience.com/identifying-duplicate-questions-on-quora-top-12-on-kaggle-4c1cf93f1c30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.3 Real world/Business Objectives and Constraints </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The cost of a mis-classification can be very high.\n",
    "2. You would want a probability of a pair of questions to be duplicates so that you can choose any threshold of choice.\n",
    "3. No strict latency concerns.\n",
    "4. Interpretability is partially important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Machine Learning Probelm </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2.1 Data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.1.1 Data Overview </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "- Data will be in a file Train.csv <br>\n",
    "- Train.csv contains 5 columns : qid1, qid2, question1, question2, is_duplicate <br>\n",
    "- Size of Train.csv - 60MB <br>\n",
    "- Number of rows in Train.csv = 404,290\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.1.2 Example Data point </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\"id\",\"qid1\",\"qid2\",\"question1\",\"question2\",\"is_duplicate\"\n",
    "\"0\",\"1\",\"2\",\"What is the step by step guide to invest in share market in india?\",\"What is the step by step guide to invest in share market?\",\"0\"\n",
    "\"1\",\"3\",\"4\",\"What is the story of Kohinoor (Koh-i-Noor) Diamond?\",\"What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\",\"0\"\n",
    "\"7\",\"15\",\"16\",\"How can I be a good geologist?\",\"What should I do to be a great geologist?\",\"1\"\n",
    "\"11\",\"23\",\"24\",\"How do I read and find my YouTube comments?\",\"How can I see all my Youtube comments?\",\"1\"\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2.2 Mapping the real world problem to an ML problem </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.2.1 Type of Machine Leaning Problem </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> It is a binary classification problem, for a given pair of questions we need to predict if they are duplicate or not. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.2.2 Performance Metric </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/c/quora-question-pairs#evaluation\n",
    "\n",
    "Metric(s): \n",
    "* log-loss : https://www.kaggle.com/wiki/LogarithmicLoss\n",
    "* Binary Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2.3 Train and Test Construction </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>  </p>\n",
    "<p> We build train and test by randomly splitting in the ratio of 70:30 or 80:20 whatever we choose as we have sufficient points to work with. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Exploratory Data Analysis </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import distance\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# This package is used for finding longest common subsequence between two strings\n",
    "# you can write your own dp code for this\n",
    "import distance\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.manifold import TSNE\n",
    "# Import the Required lib packages for WORD-Cloud generation\n",
    "# https://stackoverflow.com/questions/45625434/how-to-install-wordcloud-in-python3-6\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from os import path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.1 Reading data and basic stats </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 3822268\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/data/szr207/projects/ArqMath/gold/train.tsv\",sep='\\t')\n",
    "\n",
    "print(\"Number of data points:\",df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16020</td>\n",
       "      <td>16025</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>Assume the first form. Let I be any set and le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>16020</td>\n",
       "      <td>697264</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>I know two equivalent definitions for an onto ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16020</td>\n",
       "      <td>2645743</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>This is part of the all-important Corresponden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16020</td>\n",
       "      <td>2875568</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>I am going to answer my own question. I had a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16020</td>\n",
       "      <td>1650515</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>More informally, elements of the free semigrou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   qid1     qid2                                          question1  \\\n",
       "0   1  16020    16025  Equivalent statements of the Axiom of Choice. ...   \n",
       "1   2  16020   697264  Equivalent statements of the Axiom of Choice. ...   \n",
       "2   3  16020  2645743  Equivalent statements of the Axiom of Choice. ...   \n",
       "3   4  16020  2875568  Equivalent statements of the Axiom of Choice. ...   \n",
       "4   5  16020  1650515  Equivalent statements of the Axiom of Choice. ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Assume the first form. Let I be any set and le...             0  \n",
       "1  I know two equivalent definitions for an onto ...             0  \n",
       "2  This is part of the all-important Corresponden...             0  \n",
       "3  I am going to answer my own question. I had a ...             0  \n",
       "4  More informally, elements of the free semigrou...             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3822268 entries, 0 to 3822267\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Dtype \n",
      "---  ------        ----- \n",
      " 0   id            int64 \n",
      " 1   qid1          int64 \n",
      " 2   qid2          int64 \n",
      " 3   question1     object\n",
      " 4   question2     object\n",
      " 5   is_duplicate  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 175.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given a minimal number of data fields here, consisting of:\n",
    "\n",
    "- id:  Looks like a simple rowID\n",
    "- qid{1, 2}:  The unique ID of each question in the pair\n",
    "- question{1, 2}:  The actual textual contents of the questions.\n",
    "- is_duplicate:  The label that we are trying to predict - whether the two questions are duplicates of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.2.1 Distribution of data points among output classes</h3>\n",
    "- Number of duplicate(smilar) and non-duplicate(non similar) questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f16bbbf3dd8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(\"is_duplicate\")['id'].count().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> Total number of question pairs for training:\n",
      "   3822268\n"
     ]
    }
   ],
   "source": [
    "print('~> Total number of question pairs for training:\\n   {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> Question pairs are not Similar (is_duplicate = 0):\n",
      "   90.91%\n",
      "\n",
      "~> Question pairs are Similar (is_duplicate = 1):\n",
      "   9.09%\n"
     ]
    }
   ],
   "source": [
    "print('~> Question pairs are not Similar (is_duplicate = 0):\\n   {}%'.format(100 - round(df['is_duplicate'].mean()*100, 2)))\n",
    "print('\\n~> Question pairs are Similar (is_duplicate = 1):\\n   {}%'.format(round(df['is_duplicate'].mean()*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.2.2 Number of unique questions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of  Unique Questions are: 1257256\n",
      "\n",
      "Number of unique questions that appear more than one time: 914862 (72.76656464554554%)\n",
      "\n",
      "Max number of times a single question is repeated: 378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qids = pd.Series(df['qid1'].tolist() + df['qid2'].tolist())\n",
    "unique_qs = len(np.unique(qids))\n",
    "qs_morethan_onetime = np.sum(qids.value_counts() > 1)\n",
    "print ('Total number of  Unique Questions are: {}\\n'.format(unique_qs))\n",
    "#print len(np.unique(qids))\n",
    "\n",
    "print ('Number of unique questions that appear more than one time: {} ({}%)\\n'.format(qs_morethan_onetime,qs_morethan_onetime/unique_qs*100))\n",
    "\n",
    "print ('Max number of times a single question is repeated: {}\\n'.format(max(qids.value_counts()))) \n",
    "\n",
    "q_vals=qids.value_counts()\n",
    "\n",
    "q_vals=q_vals.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [\"unique_questions\" , \"Repeated Questions\"]\n",
    "y =  [unique_qs , qs_morethan_onetime]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title (\"Plot representing unique and repeated questions  \")\n",
    "sns.barplot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.2.3 Checking for Duplicates </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate questions 0\n"
     ]
    }
   ],
   "source": [
    "#checking whether there are any repeated pair of questions\n",
    "\n",
    "pair_duplicates = df[['qid1','qid2','is_duplicate']].groupby(['qid1','qid2']).count().reset_index()\n",
    "\n",
    "print (\"Number of duplicate questions\",(pair_duplicates).shape[0] - df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.2.4 Number of occurrences of each question </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of times a single question is repeated: 378\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.hist(qids.value_counts(), bins=160)\n",
    "\n",
    "plt.yscale('log', nonposy='clip')\n",
    "\n",
    "plt.title('Log-Histogram of question appearance counts')\n",
    "\n",
    "plt.xlabel('Number of occurences of question')\n",
    "\n",
    "plt.ylabel('Number of questions')\n",
    "\n",
    "print ('Maximum number of times a single question is repeated: {}\\n'.format(max(qids.value_counts())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.2.5 Checking for NULL values </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, qid1, qid2, question1, question2, is_duplicate]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Checking whether there are any rows with null values\n",
    "nan_rows = df[df.isnull().any(1)]\n",
    "print (nan_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are two rows with null values in question2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, qid1, qid2, question1, question2, is_duplicate]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Filling the null values with ' '\n",
    "df = df.fillna('')\n",
    "nan_rows = df[df.isnull().any(1)]\n",
    "print (nan_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3.3 Basic Feature Extraction (before cleaning) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now construct a few features like:\n",
    " - ____freq_qid1____ = Frequency of qid1's\n",
    " - ____freq_qid2____ = Frequency of qid2's \n",
    " - ____q1len____ = Length of q1\n",
    " - ____q2len____ = Length of q2\n",
    " - ____q1_n_words____ = Number of words in Question 1\n",
    " - ____q2_n_words____ = Number of words in Question 2\n",
    " - ____word_Common____ = (Number of common unique words in Question 1 and Question 2)\n",
    " - ____word_Total____ =(Total num of words in Question 1 + Total num of words in Question 2)\n",
    " - ____word_share____ = (word_common)/(word_Total)\n",
    " - ____freq_q1+freq_q2____ = sum total of frequency of qid1 and qid2 \n",
    " - ____freq_q1-freq_q2____ = absolute difference of frequency of qid1 and qid2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16020</td>\n",
       "      <td>16025</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>Assume the first form. Let I be any set and le...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>545</td>\n",
       "      <td>660</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>27.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.198529</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>16020</td>\n",
       "      <td>697264</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>I know two equivalent definitions for an onto ...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>545</td>\n",
       "      <td>606</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "      <td>14.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16020</td>\n",
       "      <td>2645743</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>This is part of the all-important Corresponden...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>545</td>\n",
       "      <td>883</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16020</td>\n",
       "      <td>2875568</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>I am going to answer my own question. I had a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>545</td>\n",
       "      <td>552</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16020</td>\n",
       "      <td>1650515</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>More informally, elements of the free semigrou...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>545</td>\n",
       "      <td>595</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>13.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.092857</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   qid1     qid2                                          question1  \\\n",
       "0   1  16020    16025  Equivalent statements of the Axiom of Choice. ...   \n",
       "1   2  16020   697264  Equivalent statements of the Axiom of Choice. ...   \n",
       "2   3  16020  2645743  Equivalent statements of the Axiom of Choice. ...   \n",
       "3   4  16020  2875568  Equivalent statements of the Axiom of Choice. ...   \n",
       "4   5  16020  1650515  Equivalent statements of the Axiom of Choice. ...   \n",
       "\n",
       "                                           question2  is_duplicate  freq_qid1  \\\n",
       "0  Assume the first form. Let I be any set and le...             0         11   \n",
       "1  I know two equivalent definitions for an onto ...             0         11   \n",
       "2  This is part of the all-important Corresponden...             0         11   \n",
       "3  I am going to answer my own question. I had a ...             0         11   \n",
       "4  More informally, elements of the free semigrou...             0         11   \n",
       "\n",
       "   freq_qid2  q1len  q2len  q1_n_words  q2_n_words  word_Common  word_Total  \\\n",
       "0          6    545    660         100         100         27.0       136.0   \n",
       "1          9    545    606         100          97         14.0       134.0   \n",
       "2          3    545    883         100         100         10.0       149.0   \n",
       "3         18    545    552         100         100         16.0       146.0   \n",
       "4          4    545    595         100         100         13.0       140.0   \n",
       "\n",
       "   word_share  freq_q1+q2  freq_q1-q2  \n",
       "0    0.198529          17           5  \n",
       "1    0.104478          20           2  \n",
       "2    0.067114          14           8  \n",
       "3    0.109589          29           7  \n",
       "4    0.092857          15           7  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    df = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    df['freq_qid1'] = df.groupby('qid1')['qid1'].transform('count') \n",
    "    df['freq_qid2'] = df.groupby('qid2')['qid2'].transform('count')\n",
    "    df['q1len'] = df['question1'].str.len() \n",
    "    df['q2len'] = df['question2'].str.len()\n",
    "    df['q1_n_words'] = df['question1'].apply(lambda row: len(row.split(\" \")))\n",
    "    df['q2_n_words'] = df['question2'].apply(lambda row: len(row.split(\" \")))\n",
    "\n",
    "    def normalized_word_Common(row):\n",
    "        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "        return 1.0 * len(w1 & w2)\n",
    "    df['word_Common'] = df.apply(normalized_word_Common, axis=1)\n",
    "\n",
    "    def normalized_word_Total(row):\n",
    "        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "        return 1.0 * (len(w1) + len(w2))\n",
    "    df['word_Total'] = df.apply(normalized_word_Total, axis=1)\n",
    "\n",
    "    def normalized_word_share(row):\n",
    "        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "        return 1.0 * len(w1 & w2)/(len(w1) + len(w2))\n",
    "    df['word_share'] = df.apply(normalized_word_share, axis=1)\n",
    "\n",
    "    df['freq_q1+q2'] = df['freq_qid1']+df['freq_qid2']\n",
    "    df['freq_q1-q2'] = abs(df['freq_qid1']-df['freq_qid2'])\n",
    "\n",
    "    df.to_csv(\"df_fe_without_preprocessing_train.csv\", index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.3.1 Analysis of some of the extracted features </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here are some questions have only one single words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum length of the questions in question1 :  6\n",
      "Minimum length of the questions in question2 :  2\n",
      "Number of Questions with minimum length [question1] : 0\n",
      "Number of Questions with minimum length [question2] : 0\n"
     ]
    }
   ],
   "source": [
    "print (\"Minimum length of the questions in question1 : \" , min(df['q1_n_words']))\n",
    "\n",
    "print (\"Minimum length of the questions in question2 : \" , min(df['q2_n_words']))\n",
    "\n",
    "print (\"Number of Questions with minimum length [question1] :\", df[df['q1_n_words']== 1].shape[0])\n",
    "print (\"Number of Questions with minimum length [question2] :\", df[df['q2_n_words']== 1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 3.3.1.1 Feature: word_share </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.violinplot(x = 'is_duplicate', y = 'word_share', data = df[0:])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(df[df['is_duplicate'] == 1.0]['word_share'][0:] , label = \"1\", color = 'red')\n",
    "sns.distplot(df[df['is_duplicate'] == 0.0]['word_share'][0:] , label = \"0\" , color = 'blue' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The distributions for normalized word_share have some overlap on the far right-hand side, i.e., there are quite a lot of questions with high word similarity\n",
    "- The average word share and Common no. of words of qid1 and qid2 is more when they are duplicate(Similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 3.3.1.2 Feature: word_Common </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.violinplot(x = 'is_duplicate', y = 'word_Common', data = df[0:])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(df[df['is_duplicate'] == 1.0]['word_Common'][0:] , label = \"1\", color = 'red')\n",
    "sns.distplot(df[df['is_duplicate'] == 0.0]['word_Common'][0:] , label = \"0\" , color = 'blue' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The distributions of the word_Common feature in similar and non-similar questions are highly overlapping </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/12468179/unicodedecodeerror-utf8-codec-cant-decode-byte-0x9c\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    df = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "    df = df.fillna('')\n",
    "    df.head()\n",
    "else:\n",
    "    print(\"get df_fe_without_preprocessing_train.csv from drive or run the previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16020</td>\n",
       "      <td>16025</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>Assume the first form. Let I be any set and le...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>545</td>\n",
       "      <td>660</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>27.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.198529</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>16020</td>\n",
       "      <td>697264</td>\n",
       "      <td>Equivalent statements of the Axiom of Choice. ...</td>\n",
       "      <td>I know two equivalent definitions for an onto ...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>545</td>\n",
       "      <td>606</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "      <td>14.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   qid1    qid2                                          question1  \\\n",
       "0   1  16020   16025  Equivalent statements of the Axiom of Choice. ...   \n",
       "1   2  16020  697264  Equivalent statements of the Axiom of Choice. ...   \n",
       "\n",
       "                                           question2  is_duplicate  freq_qid1  \\\n",
       "0  Assume the first form. Let I be any set and le...             0         11   \n",
       "1  I know two equivalent definitions for an onto ...             0         11   \n",
       "\n",
       "   freq_qid2  q1len  q2len  q1_n_words  q2_n_words  word_Common  word_Total  \\\n",
       "0          6    545    660         100         100         27.0       136.0   \n",
       "1          9    545    606         100          97         14.0       134.0   \n",
       "\n",
       "   word_share  freq_q1+q2  freq_q1-q2  \n",
       "0    0.198529          17           5  \n",
       "1    0.104478          20           2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.4 Preprocessing of Text </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocessing:\n",
    "    - Removing html tags \n",
    "    - Removing Punctuations\n",
    "    - Performing stemming\n",
    "    - Removing Stopwords\n",
    "    - Expanding contractions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the results in 4 decemal points\n",
    "SAFE_DIV = 0.0001 \n",
    "\n",
    "STOP_WORDS = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    \n",
    "    \n",
    "    porter = PorterStemmer()\n",
    "    pattern = re.compile('\\W')\n",
    "    \n",
    "    if type(x) == type(''):\n",
    "        x = re.sub(pattern, ' ', x)\n",
    "    \n",
    "    \n",
    "    if type(x) == type(''):\n",
    "        x = porter.stem(x)\n",
    "        example1 = BeautifulSoup(x)\n",
    "        x = example1.get_text()\n",
    "               \n",
    "    \n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to Compute and get the features : With 2 parameters of Question 1 and Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.5 Advanced Feature Extraction (NLP and Fuzzy Features) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition:\n",
    "- __Token__: You get a token by splitting sentence a space\n",
    "- __Stop_Word__ : stop words as per NLTK.\n",
    "- __Word__ : A token that is not a stop_word\n",
    "\n",
    "\n",
    "Features:\n",
    "- __cwc_min__ :  Ratio of common_word_count to min lenghth of word count of Q1 and Q2 <br>cwc_min = common_word_count / (min(len(q1_words), len(q2_words))\n",
    "<br>\n",
    "<br>\n",
    "- __cwc_max__ :  Ratio of common_word_count to max lenghth of word count of Q1 and Q2 <br>cwc_max = common_word_count / (max(len(q1_words), len(q2_words))\n",
    "<br>\n",
    "<br>\n",
    "- __csc_min__ :  Ratio of common_stop_count to min lenghth of stop count of Q1 and Q2 <br> csc_min = common_stop_count / (min(len(q1_stops), len(q2_stops))\n",
    "<br>\n",
    "<br>\n",
    "- __csc_max__ :  Ratio of common_stop_count to max lenghth of stop count of Q1 and Q2<br>csc_max = common_stop_count / (max(len(q1_stops), len(q2_stops))\n",
    "<br>\n",
    "<br>\n",
    "- __ctc_min__ :  Ratio of common_token_count to min lenghth of token count of Q1 and Q2<br>ctc_min = common_token_count / (min(len(q1_tokens), len(q2_tokens))\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- __ctc_max__ :  Ratio of common_token_count to max lenghth of token count of Q1 and Q2<br>ctc_max = common_token_count / (max(len(q1_tokens), len(q2_tokens))\n",
    "<br>\n",
    "<br>\n",
    "        \n",
    "- __last_word_eq__ :  Check if Last word of both questions is equal or not<br>last_word_eq = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- __first_word_eq__ :  Check if First word of both questions is equal or not<br>first_word_eq = int(q1_tokens[0] == q2_tokens[0])\n",
    "<br>\n",
    "<br>\n",
    "        \n",
    "- __abs_len_diff__ :  Abs. length difference<br>abs_len_diff = abs(len(q1_tokens) - len(q2_tokens))\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- __mean_len__ :  Average Token Length of both Questions<br>mean_len = (len(q1_tokens) + len(q2_tokens))/2\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "- __fuzz_ratio__ :  https://github.com/seatgeek/fuzzywuzzy#usage\n",
    "http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "- __fuzz_partial_ratio__ :  https://github.com/seatgeek/fuzzywuzzy#usage\n",
    "http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "- __token_sort_ratio__ : https://github.com/seatgeek/fuzzywuzzy#usage\n",
    "http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "- __token_set_ratio__ : https://github.com/seatgeek/fuzzywuzzy#usage\n",
    "http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- __longest_substr_ratio__ :  Ratio of length longest common substring to min lenghth of token count of Q1 and Q2<br>longest_substr_ratio = len(longest common substring) / (min(len(q1_tokens), len(q2_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_features(q1, q2):\n",
    "    token_features = [0.0]*10\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "\n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    #Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    \n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    \n",
    "    # Last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    \n",
    "    # First word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    #Average Token Length of both Questions\n",
    "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    return token_features\n",
    "\n",
    "# get the Longest Common sub string\n",
    "\n",
    "def get_longest_substr_ratio(a, b):\n",
    "    strs = list(distance.lcsubstrings(a, b))\n",
    "    if len(strs) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(strs[0]) / (min(len(a), len(b)) + 1)\n",
    "\n",
    "def extract_features(df):\n",
    "    # preprocessing each question\n",
    "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
    "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
    "\n",
    "    print(\"token features...\")\n",
    "    \n",
    "    # Merging Features with dataset\n",
    "    \n",
    "    token_features = df.apply(lambda x: get_token_features(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    \n",
    "    df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
    "    df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
    "    df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
    "    df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
    "    df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
    "    df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
    "    df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
    "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
    "    df[\"abs_len_diff\"]  = list(map(lambda x: x[8], token_features))\n",
    "    df[\"mean_len\"]      = list(map(lambda x: x[9], token_features))\n",
    "   \n",
    "    #Computing Fuzzy Features and Merging with Dataset\n",
    "    \n",
    "    # do read this blog: http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
    "    # https://stackoverflow.com/questions/31806695/when-to-use-which-fuzz-function-to-compare-2-strings\n",
    "    # https://github.com/seatgeek/fuzzywuzzy\n",
    "    print(\"fuzzy features..\")\n",
    "\n",
    "    df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    # The token sort approach involves tokenizing the string in question, sorting the tokens alphabetically, and \n",
    "    # then joining them back into a string We then compare the transformed strings with a simple ratio().\n",
    "    df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_ratio\"]            = df.apply(lambda x: fuzz.QRatio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for train:\n",
      "token features...\n",
      "fuzzy features..\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    df = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "    df.fillna('')\n",
    "else:\n",
    "    print(\"Extracting features for train:\")\n",
    "    df = pd.read_csv(\"/data/szr207/projects/ArqMath/gold/train.tsv\",sep='\\t')\n",
    "    df = extract_features(df)\n",
    "    df.to_csv(\"nlp_features_train.csv\", index=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.5.1 Analysis of extracted features </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating Word Cloud of Duplicates and Non-Duplicates Question pairs\n",
    "- We can observe the most frequent occuring words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicate = df[df['is_duplicate'] == 1]\n",
    "dfp_nonduplicate = df[df['is_duplicate'] == 0]\n",
    "\n",
    "# Converting 2d array of q1 and q2 and flatten the array: like {{1,2},{3,4}} to {1,2,3,4}\n",
    "p = np.dstack([df_duplicate[\"question1\"], df_duplicate[\"question2\"]]).flatten()\n",
    "n = np.dstack([dfp_nonduplicate[\"question1\"], dfp_nonduplicate[\"question2\"]]).flatten()\n",
    "\n",
    "print (\"Number of data points in class 1 (duplicate pairs) :\",len(p))\n",
    "print (\"Number of data points in class 0 (non duplicate pairs) :\",len(n))\n",
    "\n",
    "#Saving the np array into a text file\n",
    "np.savetxt('train_p.txt', p, delimiter=' ', fmt='%s')\n",
    "np.savetxt('train_n.txt', n, delimiter=' ', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the text files and removing the Stop Words:\n",
    "d = path.dirname('.')\n",
    "\n",
    "textp_w = open(path.join(d, 'train_p.txt')).read()\n",
    "textn_w = open(path.join(d, 'train_n.txt')).read()\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add(\"said\")\n",
    "stopwords.add(\"br\")\n",
    "stopwords.add(\" \")\n",
    "stopwords.remove(\"not\")\n",
    "\n",
    "stopwords.remove(\"no\")\n",
    "#stopwords.remove(\"good\")\n",
    "#stopwords.remove(\"love\")\n",
    "stopwords.remove(\"like\")\n",
    "#stopwords.remove(\"best\")\n",
    "#stopwords.remove(\"!\")\n",
    "print (\"Total number of words in duplicate pair questions :\",len(textp_w))\n",
    "print (\"Total number of words in non duplicate pair questions :\",len(textn_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Word Clouds generated from  duplicate pair question's text __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"white\", max_words=len(textp_w), stopwords=stopwords)\n",
    "wc.generate(textp_w)\n",
    "print (\"Word Cloud for Duplicate Question pairs\")\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Word Clouds generated from non duplicate pair question's text __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"white\", max_words=len(textn_w),stopwords=stopwords)\n",
    "# generate word cloud\n",
    "wc.generate(textn_w)\n",
    "print (\"Word Cloud for non-Duplicate Question pairs:\")\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 3.5.1.2 Pair plot of features ['ctc_min', 'cwc_min', 'csc_min', 'token_sort_ratio'] </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.shape[0]\n",
    "sns.pairplot(df[['ctc_min', 'cwc_min', 'csc_min', 'token_sort_ratio', 'is_duplicate']][0:n], hue='is_duplicate', vars=['ctc_min', 'cwc_min', 'csc_min', 'token_sort_ratio'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the token_sort_ratio\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.violinplot(x = 'is_duplicate', y = 'token_sort_ratio', data = df[0:] , )\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(df[df['is_duplicate'] == 1.0]['token_sort_ratio'][0:] , label = \"1\", color = 'red')\n",
    "sns.distplot(df[df['is_duplicate'] == 0.0]['token_sort_ratio'][0:] , label = \"0\" , color = 'blue' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.violinplot(x = 'is_duplicate', y = 'fuzz_ratio', data = df[0:] , )\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(df[df['is_duplicate'] == 1.0]['fuzz_ratio'][0:] , label = \"1\", color = 'red')\n",
    "sns.distplot(df[df['is_duplicate'] == 0.0]['fuzz_ratio'][0:] , label = \"0\" , color = 'blue' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.5.2 Visualization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TSNE for Dimentionality reduction for 15 Features(Generated after cleaning the data) to 3 dimention\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dfp_subsampled = df[0:5000]\n",
    "X = MinMaxScaler().fit_transform(dfp_subsampled[['cwc_min', 'cwc_max', 'csc_min', 'csc_max' , 'ctc_min' , 'ctc_max' , 'last_word_eq', 'first_word_eq' , 'abs_len_diff' , 'mean_len' , 'token_set_ratio' , 'token_sort_ratio' ,  'fuzz_ratio' , 'fuzz_partial_ratio' , 'longest_substr_ratio']])\n",
    "y = dfp_subsampled['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne2d = TSNE(\n",
    "    n_components=2,\n",
    "    init='random', # pca\n",
    "    random_state=101,\n",
    "    method='barnes_hut',\n",
    "    n_iter=1000,\n",
    "    verbose=2,\n",
    "    angle=0.5\n",
    ").fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x':tsne2d[:,0], 'y':tsne2d[:,1] ,'label':y})\n",
    "\n",
    "# draw the plot in appropriate place in the grid\n",
    "sns.lmplot(data=df, x='x', y='y', hue='label', fit_reg=False, size=8,palette=\"Set1\",markers=['s','o'])\n",
    "plt.title(\"perplexity : {} and max_iter : {}\".format(30, 1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne3d = TSNE(\n",
    "    n_components=3,\n",
    "    init='random', # pca\n",
    "    random_state=101,\n",
    "    method='barnes_hut',\n",
    "    n_iter=1000,\n",
    "    verbose=2,\n",
    "    angle=0.5\n",
    ").fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Scatter3d(\n",
    "    x=tsne3d[:,0],\n",
    "    y=tsne3d[:,1],\n",
    "    z=tsne3d[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode='diameter',\n",
    "        color = y,\n",
    "        colorscale = 'Portland',\n",
    "        colorbar = dict(title = 'duplicate'),\n",
    "        line=dict(color='rgb(255, 255, 255)'),\n",
    "        opacity=0.75\n",
    "    )\n",
    ")\n",
    "\n",
    "data=[trace1]\n",
    "layout=dict(height=800, width=800, title='3d embedding with engineered features')\n",
    "fig=dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='3DBubble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.6 Featurizing text data with tfidf weighted word-vectors </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# exctract word2vec vectors\n",
    "# https://github.com/explosion/spaCy/issues/1721\n",
    "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid decoding problems\n",
    "df = pd.read_csv(\"/data/szr207/projects/ArqMath/gold/train.tsv\",sep='\\t')\n",
    "\n",
    "# df = pd.read_csv(\"train.csv\" )\n",
    " \n",
    "# encode questions to unicode\n",
    "# https://stackoverflow.com/a/6812069\n",
    "# ----------------- python 2 ---------------------\n",
    "# df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# ----------------- python 3 ---------------------\n",
    "df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "df['question2'] = df['question2'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "questions = list(df['question1']) + list(df['question2'])\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False,)\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n",
    "- here we use a pre-trained GLOVE model which comes free with \"Spacy\".  https://spacy.io/usage/vectors-similarity\n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(list(df['question1'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), 384])\n",
    "    for word1 in doc1:\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1 += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "df['q1_feats_m'] = list(vecs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs2 = []\n",
    "for qu2 in tqdm(list(df['question2'])):\n",
    "    doc2 = nlp(qu2) \n",
    "    mean_vec2 = np.zeros([len(doc2), 384])\n",
    "    for word2 in doc2:\n",
    "        # word2vec\n",
    "        vec2 = word2.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word2)]\n",
    "        except:\n",
    "            #print word\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec2 += vec2 * idf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    vecs2.append(mean_vec2)\n",
    "df['q2_feats_m'] = list(vecs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n",
    "\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3 = df.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3_q1 = pd.DataFrame(df3.q1_feats_m.values.tolist(), index= df3.index)\n",
    "df3_q2 = pd.DataFrame(df3.q2_feats_m.values.tolist(), index= df3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of nlp features\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data before preprocessing \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions 1 tfidf weighted word2vec\n",
    "df3_q1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions 2 tfidf weighted word2vec\n",
    "df3_q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of features in nlp dataframe :\", df1.shape[1])\n",
    "print(\"Number of features in preprocessed dataframe :\", df2.shape[1])\n",
    "print(\"Number of features in question1 w2v  dataframe :\", df3_q1.shape[1])\n",
    "print(\"Number of features in question2 w2v  dataframe :\", df3_q2.shape[1])\n",
    "print(\"Number of features in final dataframe  :\", df1.shape[1]+df2.shape[1]+df3_q1.shape[1]+df3_q2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the final features to csv file\n",
    "if not os.path.isfile('final_features.csv'):\n",
    "    df3_q1['id']=df1['id']\n",
    "    df3_q2['id']=df1['id']\n",
    "    df1  = df1.merge(df2, on='id',how='left')\n",
    "    df2  = df3_q1.merge(df3_q2, on='id',how='left')\n",
    "    result  = df1.merge(df2, on='id',how='left')\n",
    "    result.to_csv('final_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import csv\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4. Machine Learning Models </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.1 Reading data from file and storing into sql table </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating db file from csv\n",
    "if not os.path.isfile('train.db'):\n",
    "    disk_engine = create_engine('sqlite:///train.db')\n",
    "    start = dt.datetime.now()\n",
    "    chunksize = 180000\n",
    "    j = 0\n",
    "    index_start = 1\n",
    "    for df in pd.read_csv('final_features.csv', names=['Unnamed: 0','id','is_duplicate','cwc_min','cwc_max','csc_min','csc_max','ctc_min','ctc_max','last_word_eq','first_word_eq','abs_len_diff','mean_len','token_set_ratio','token_sort_ratio','fuzz_ratio','fuzz_partial_ratio','longest_substr_ratio','freq_qid1','freq_qid2','q1len','q2len','q1_n_words','q2_n_words','word_Common','word_Total','word_share','freq_q1+q2','freq_q1-q2','0_x','1_x','2_x','3_x','4_x','5_x','6_x','7_x','8_x','9_x','10_x','11_x','12_x','13_x','14_x','15_x','16_x','17_x','18_x','19_x','20_x','21_x','22_x','23_x','24_x','25_x','26_x','27_x','28_x','29_x','30_x','31_x','32_x','33_x','34_x','35_x','36_x','37_x','38_x','39_x','40_x','41_x','42_x','43_x','44_x','45_x','46_x','47_x','48_x','49_x','50_x','51_x','52_x','53_x','54_x','55_x','56_x','57_x','58_x','59_x','60_x','61_x','62_x','63_x','64_x','65_x','66_x','67_x','68_x','69_x','70_x','71_x','72_x','73_x','74_x','75_x','76_x','77_x','78_x','79_x','80_x','81_x','82_x','83_x','84_x','85_x','86_x','87_x','88_x','89_x','90_x','91_x','92_x','93_x','94_x','95_x','96_x','97_x','98_x','99_x','100_x','101_x','102_x','103_x','104_x','105_x','106_x','107_x','108_x','109_x','110_x','111_x','112_x','113_x','114_x','115_x','116_x','117_x','118_x','119_x','120_x','121_x','122_x','123_x','124_x','125_x','126_x','127_x','128_x','129_x','130_x','131_x','132_x','133_x','134_x','135_x','136_x','137_x','138_x','139_x','140_x','141_x','142_x','143_x','144_x','145_x','146_x','147_x','148_x','149_x','150_x','151_x','152_x','153_x','154_x','155_x','156_x','157_x','158_x','159_x','160_x','161_x','162_x','163_x','164_x','165_x','166_x','167_x','168_x','169_x','170_x','171_x','172_x','173_x','174_x','175_x','176_x','177_x','178_x','179_x','180_x','181_x','182_x','183_x','184_x','185_x','186_x','187_x','188_x','189_x','190_x','191_x','192_x','193_x','194_x','195_x','196_x','197_x','198_x','199_x','200_x','201_x','202_x','203_x','204_x','205_x','206_x','207_x','208_x','209_x','210_x','211_x','212_x','213_x','214_x','215_x','216_x','217_x','218_x','219_x','220_x','221_x','222_x','223_x','224_x','225_x','226_x','227_x','228_x','229_x','230_x','231_x','232_x','233_x','234_x','235_x','236_x','237_x','238_x','239_x','240_x','241_x','242_x','243_x','244_x','245_x','246_x','247_x','248_x','249_x','250_x','251_x','252_x','253_x','254_x','255_x','256_x','257_x','258_x','259_x','260_x','261_x','262_x','263_x','264_x','265_x','266_x','267_x','268_x','269_x','270_x','271_x','272_x','273_x','274_x','275_x','276_x','277_x','278_x','279_x','280_x','281_x','282_x','283_x','284_x','285_x','286_x','287_x','288_x','289_x','290_x','291_x','292_x','293_x','294_x','295_x','296_x','297_x','298_x','299_x','300_x','301_x','302_x','303_x','304_x','305_x','306_x','307_x','308_x','309_x','310_x','311_x','312_x','313_x','314_x','315_x','316_x','317_x','318_x','319_x','320_x','321_x','322_x','323_x','324_x','325_x','326_x','327_x','328_x','329_x','330_x','331_x','332_x','333_x','334_x','335_x','336_x','337_x','338_x','339_x','340_x','341_x','342_x','343_x','344_x','345_x','346_x','347_x','348_x','349_x','350_x','351_x','352_x','353_x','354_x','355_x','356_x','357_x','358_x','359_x','360_x','361_x','362_x','363_x','364_x','365_x','366_x','367_x','368_x','369_x','370_x','371_x','372_x','373_x','374_x','375_x','376_x','377_x','378_x','379_x','380_x','381_x','382_x','383_x','0_y','1_y','2_y','3_y','4_y','5_y','6_y','7_y','8_y','9_y','10_y','11_y','12_y','13_y','14_y','15_y','16_y','17_y','18_y','19_y','20_y','21_y','22_y','23_y','24_y','25_y','26_y','27_y','28_y','29_y','30_y','31_y','32_y','33_y','34_y','35_y','36_y','37_y','38_y','39_y','40_y','41_y','42_y','43_y','44_y','45_y','46_y','47_y','48_y','49_y','50_y','51_y','52_y','53_y','54_y','55_y','56_y','57_y','58_y','59_y','60_y','61_y','62_y','63_y','64_y','65_y','66_y','67_y','68_y','69_y','70_y','71_y','72_y','73_y','74_y','75_y','76_y','77_y','78_y','79_y','80_y','81_y','82_y','83_y','84_y','85_y','86_y','87_y','88_y','89_y','90_y','91_y','92_y','93_y','94_y','95_y','96_y','97_y','98_y','99_y','100_y','101_y','102_y','103_y','104_y','105_y','106_y','107_y','108_y','109_y','110_y','111_y','112_y','113_y','114_y','115_y','116_y','117_y','118_y','119_y','120_y','121_y','122_y','123_y','124_y','125_y','126_y','127_y','128_y','129_y','130_y','131_y','132_y','133_y','134_y','135_y','136_y','137_y','138_y','139_y','140_y','141_y','142_y','143_y','144_y','145_y','146_y','147_y','148_y','149_y','150_y','151_y','152_y','153_y','154_y','155_y','156_y','157_y','158_y','159_y','160_y','161_y','162_y','163_y','164_y','165_y','166_y','167_y','168_y','169_y','170_y','171_y','172_y','173_y','174_y','175_y','176_y','177_y','178_y','179_y','180_y','181_y','182_y','183_y','184_y','185_y','186_y','187_y','188_y','189_y','190_y','191_y','192_y','193_y','194_y','195_y','196_y','197_y','198_y','199_y','200_y','201_y','202_y','203_y','204_y','205_y','206_y','207_y','208_y','209_y','210_y','211_y','212_y','213_y','214_y','215_y','216_y','217_y','218_y','219_y','220_y','221_y','222_y','223_y','224_y','225_y','226_y','227_y','228_y','229_y','230_y','231_y','232_y','233_y','234_y','235_y','236_y','237_y','238_y','239_y','240_y','241_y','242_y','243_y','244_y','245_y','246_y','247_y','248_y','249_y','250_y','251_y','252_y','253_y','254_y','255_y','256_y','257_y','258_y','259_y','260_y','261_y','262_y','263_y','264_y','265_y','266_y','267_y','268_y','269_y','270_y','271_y','272_y','273_y','274_y','275_y','276_y','277_y','278_y','279_y','280_y','281_y','282_y','283_y','284_y','285_y','286_y','287_y','288_y','289_y','290_y','291_y','292_y','293_y','294_y','295_y','296_y','297_y','298_y','299_y','300_y','301_y','302_y','303_y','304_y','305_y','306_y','307_y','308_y','309_y','310_y','311_y','312_y','313_y','314_y','315_y','316_y','317_y','318_y','319_y','320_y','321_y','322_y','323_y','324_y','325_y','326_y','327_y','328_y','329_y','330_y','331_y','332_y','333_y','334_y','335_y','336_y','337_y','338_y','339_y','340_y','341_y','342_y','343_y','344_y','345_y','346_y','347_y','348_y','349_y','350_y','351_y','352_y','353_y','354_y','355_y','356_y','357_y','358_y','359_y','360_y','361_y','362_y','363_y','364_y','365_y','366_y','367_y','368_y','369_y','370_y','371_y','372_y','373_y','374_y','375_y','376_y','377_y','378_y','379_y','380_y','381_y','382_y','383_y'], chunksize=chunksize, iterator=True, encoding='utf-8', ):\n",
    "        df.index += index_start\n",
    "        j+=1\n",
    "        print('{} rows'.format(j*chunksize))\n",
    "        df.to_sql('data', disk_engine, if_exists='append')\n",
    "        index_start = df.index[-1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://www.sqlitetutorial.net/sqlite-python/create-tables/\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return None\n",
    "\n",
    "\n",
    "def checkTableExists(dbcon):\n",
    "    cursr = dbcon.cursor()\n",
    "    str = \"select name from sqlite_master where type='table'\"\n",
    "    table_names = cursr.execute(str)\n",
    "    print(\"Tables in the databse:\")\n",
    "    tables =table_names.fetchall() \n",
    "    print(tables[0][0])\n",
    "    return(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_db = 'train.db'\n",
    "conn_r = create_connection(read_db)\n",
    "checkTableExists(conn_r)\n",
    "conn_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to sample data according to the computing power you have\n",
    "if os.path.isfile(read_db):\n",
    "    conn_r = create_connection(read_db)\n",
    "    if conn_r is not None:\n",
    "        # for selecting first 1M rows\n",
    "        # data = pd.read_sql_query(\"\"\"SELECT * FROM data LIMIT 100001;\"\"\", conn_r)\n",
    "        \n",
    "        # for selecting random points\n",
    "        data = pd.read_sql_query(\"SELECT * From data ;\", conn_r)\n",
    "        conn_r.commit()\n",
    "        conn_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first row \n",
    "data.drop(data.index[0], inplace=True)\n",
    "y_true = data['is_duplicate']\n",
    "data.drop(['Unnamed: 0', 'id','index','is_duplicate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after we read from sql table each entry was read it as a string\n",
    "# we convert all the features into numaric before we apply any model\n",
    "cols = list(data.columns)\n",
    "data = pd.DataFrame(np.array(data.values,dtype=np.float64),columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(map(int, y_true.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.3 Random train test split( 70:30) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(data, y_true, stratify=y_true, test_size=0.3,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of data points in train data :\",X_train.shape)\n",
    "print(\"Number of data points in test data :\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*10, \"Distribution of output variable in train data\", \"-\"*10)\n",
    "train_distr = Counter(y_train)\n",
    "train_len = len(y_train)\n",
    "print(\"Class 0: \",int(train_distr[0])/train_len,\"Class 1: \", int(train_distr[1])/train_len)\n",
    "print(\"-\"*10, \"Distribution of output variable in train data\", \"-\"*10)\n",
    "test_distr = Counter(y_test)\n",
    "test_len = len(y_test)\n",
    "print(\"Class 0: \",int(test_distr[1])/test_len, \"Class 1: \",int(test_distr[1])/test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the confusion matrices given y_i, y_i_hat.\n",
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    #divid each element of the confusion matrix with the sum of elements in that column\n",
    "    \n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.T = [[1, 3],\n",
    "    #        [2, 4]]\n",
    "    # C.sum(axis = 1)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =1) = [[3, 7]]\n",
    "    # ((C.T)/(C.sum(axis=1))) = [[1/3, 3/7]\n",
    "    #                           [2/3, 4/7]]\n",
    "\n",
    "    # ((C.T)/(C.sum(axis=1))).T = [[1/3, 2/3]\n",
    "    #                           [3/7, 4/7]]\n",
    "    # sum of row elements = 1\n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "    #divid each element of the confusion matrix with the sum of elements in that row\n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.sum(axis = 0)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =0) = [[4, 6]]\n",
    "    # (C/C.sum(axis=0)) = [[1/4, 2/6],\n",
    "    #                      [3/4, 4/6]] \n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    labels = [1,2]\n",
    "    # representing A in heatmap format\n",
    "    cmap=sns.light_palette(\"blue\")\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Precision matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # representing B in heatmap format\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Recall matrix\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.4 Building a random model (Finding worst-case log-loss) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to generate 9 numbers and the sum of numbers should be 1\n",
    "# one solution is to genarate 9 numbers and divide each of the numbers by their sum\n",
    "# ref: https://stackoverflow.com/a/18662466/4084039\n",
    "# we create a output array that has exactly same size as the CV data\n",
    "predicted_y = np.zeros((test_len,2))\n",
    "for i in range(test_len):\n",
    "    rand_probs = np.random.rand(1,2)\n",
    "    predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(\"Log loss on Test Data using Random Model\",log_loss(y_test, predicted_y, eps=1e-15))\n",
    "\n",
    "predicted_y =np.argmax(predicted_y, axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.4 Logistic Regression with hyperparameter tuning </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD is sensitive to feature scaling, so did scaling and tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "X_train_sc = scale.fit_transform(X_train)\n",
    "X_test_sc = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train_sc, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train_sc, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "np.random.seed(45)\n",
    "alpha = np.random.uniform(0.0006,0.006,14)\n",
    "alpha = np.round(alpha,6)\n",
    "alpha.sort()\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train_sc, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train_sc, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.5 Linear SVM with hyperparameter tuning </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l1', loss='hinge', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train_sc, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "    log_error_array.append(log_loss(y_test, predict_y,eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l1', loss='hinge', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train_sc, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='hinge', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train_sc, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "    log_error_array.append(log_loss(y_test, predict_y,eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train_sc, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "np.random.seed(25)\n",
    "alpha = np.random.uniform(0.002,0.03,14)\n",
    "alpha = np.round(alpha,5)\n",
    "alpha.sort()\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='hinge', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train_sc, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "    log_error_array.append(log_loss(y_test, predict_y,eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train_sc, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.6 Random Forest </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [100,150,200,300,400,600,800]\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "for i in estimators:\n",
    "    clf = RFC(n_estimators=i,n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predict_y = clf.predict_proba(X_train)\n",
    "    log_loss_train = log_loss(y_train, predict_y, eps=1e-15)\n",
    "    train_scores.append(log_loss_train)\n",
    "    predict_y = clf.predict_proba(X_test)\n",
    "    log_loss_test = log_loss(y_test, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('estimators = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)\n",
    "plt.plot(estimators,train_scores,label='Train Log Loss')\n",
    "plt.plot(estimators,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('estimators') n  \n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Depth = [5,10,12,15,20,25,50]\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "for i in Depth:\n",
    "    clf = RFC(n_estimators=100,max_depth=i,n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predict_y = clf.predict_proba(X_train)\n",
    "    log_loss_train = log_loss(y_train, predict_y, eps=1e-15)\n",
    "    train_scores.append(log_loss_train)\n",
    "    predict_y = clf.predict_proba(X_test)\n",
    "    log_loss_test = log_loss(y_test, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('Depth = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)\n",
    "plt.plot(Depth,train_scores,label='Train Log Loss')\n",
    "plt.plot(Depth,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('Depth') \n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [100,150,200,300,400,600,800]\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "for i in estimators:\n",
    "    clf = RFC(n_estimators=i,max_depth=11,n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predict_y = clf.predict_proba(X_train)\n",
    "    log_loss_train = log_loss(y_train, predict_y, eps=1e-15)\n",
    "    train_scores.append(log_loss_train)\n",
    "    predict_y = clf.predict_proba(X_test)\n",
    "    log_loss_test = log_loss(y_test, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('estimators = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)\n",
    "plt.plot(estimators,train_scores,label='Train Log Loss')\n",
    "plt.plot(estimators,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('estimators') \n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.7 XGBoost </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [100,150,200,300,400,600,800]\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "for i in depths:\n",
    "    clf = xgb.XGBClassifier(max_depth=3,learning_rate=0.1,n_estimators=i,n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predict_y = clf.predict_proba(X_train)\n",
    "    log_loss_train = log_loss(y_train, predict_y, eps=1e-15)\n",
    "    train_scores.append(log_loss_train)\n",
    "    predict_y = clf.predict_proba(X_test)\n",
    "    log_loss_test = log_loss(y_test, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('estimators = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)\n",
    "plt.plot(estimators,train_scores,label='Train Log Loss')\n",
    "plt.plot(estimators,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('estimators')\n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "train_scores = []\n",
    "etas = [0.05,0.1,0.15,0.2,0.25,0.3]\n",
    "for i in etas:\n",
    "    clf = xgb.XGBClassifier(max_depth=3,learning_rate=i,n_estimators=350,n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predict_y = clf.predict_proba(X_train)\n",
    "    log_loss_train = log_loss(y_train, predict_y, eps=1e-15)\n",
    "    train_scores.append(log_loss_train)\n",
    "    predict_y = clf.predict_proba(X_test)\n",
    "    log_loss_test = log_loss(y_test, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('Learning Rate = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)\n",
    "plt.plot(etas,train_scores,label='Train Log Loss')\n",
    "plt.plot(etas,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('Learning rate')\n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "train_scores = []\n",
    "alpha = [0.5,1,5,10,50,100,150]\n",
    "for i in alpha:\n",
    "    clf = xgb.XGBClassifier(max_depth=3,learning_rate=0.65,n_estimators=370,reg_alpha=i,n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predict_y = clf.predict_proba(X_train)\n",
    "    log_loss_train = log_loss(y_train, predict_y, eps=1e-15)\n",
    "    train_scores.append(log_loss_train)\n",
    "    predict_y = clf.predict_proba(X_test)\n",
    "    log_loss_test = log_loss(y_test, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('reg_alpha = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)\n",
    "plt.plot(alpha,train_scores,label='Train Log Loss')\n",
    "plt.plot(alpha,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('reg_alpha')\n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(max_depth=3,learning_rate=0.02,n_estimators=400,n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predict_y = clf.predict_proba(X_test)\n",
    "print(\"The test log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampled data and did further hyperparam truning because of time constraints. random search for 15 models took around one day and then my system is not responding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to sample data according to the computing power you have\n",
    "if os.path.isfile(read_db):\n",
    "    conn_r = create_connection(read_db)\n",
    "    if conn_r is not None:\n",
    "        # for selecting first 1M rows\n",
    "        # data = pd.read_sql_query(\"\"\"SELECT * FROM data LIMIT 100001;\"\"\", conn_r)\n",
    "        \n",
    "        # for selecting random points\n",
    "        data = pd.read_sql_query(\"SELECT * From data LIMIT 100001;\", conn_r)\n",
    "        conn_r.commit()\n",
    "        conn_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first row \n",
    "data.drop(data.index[0], inplace=True)\n",
    "y_true = data['is_duplicate']\n",
    "data.drop(['Unnamed: 0', 'id','index','is_duplicate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after we read from sql table each entry was read it as a string\n",
    "# we convert all the features into numaric before we apply any model\n",
    "cols = list(data.columns)\n",
    "data = pd.DataFrame(np.array(data.values,dtype=np.float64),columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(map(int, y_true.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(data, y_true, stratify=y_true, test_size=0.3,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of data points in train data :\",X_train.shape)\n",
    "print(\"Number of data points in test data :\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [100,150,200,300,400,600,800]\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "for i in estimators:\n",
    "    clf = xgb.XGBClassifier(max_depth=3,learning_rate=0.1,n_estimators=i,n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predict_y = clf.predict_proba(X_train)\n",
    "    log_loss_train = log_loss(y_train, predict_y, eps=1e-15)\n",
    "    train_scores.append(log_loss_train)\n",
    "    predict_y = clf.predict_proba(X_test)\n",
    "    log_loss_test = log_loss(y_test, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('estimators = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)\n",
    "plt.plot(estimators,train_scores,label='Train Log Loss')\n",
    "plt.plot(estimators,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('estimators')\n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "train_scores = []\n",
    "etas = [0.05,0.1,0.15,0.2,0.25,0.3]\n",
    "for i in etas:\n",
    "    clf = xgb.XGBClassifier(max_depth=3,learning_rate=i,n_estimators=250,n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predict_y = clf.predict_proba(X_train)\n",
    "    log_loss_train = log_loss(y_train, predict_y, eps=1e-15)\n",
    "    train_scores.append(log_loss_train)\n",
    "    predict_y = clf.predict_proba(X_test)\n",
    "    log_loss_test = log_loss(y_test, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('Learning Rate = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)\n",
    "plt.plot(etas,train_scores,label='Train Log Loss')\n",
    "plt.plot(etas,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('Learning rate')\n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "train_scores = []\n",
    "alpha = [0.5,1,5,10,50,100,150]\n",
    "for i in alpha:\n",
    "    clf = xgb.XGBClassifier(max_depth=3,learning_rate=0.95,n_estimators=250,reg_alpha=i,n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predict_y = clf.predict_proba(X_train)\n",
    "    log_loss_train = log_loss(y_train, predict_y, eps=1e-15)\n",
    "    train_scores.append(log_loss_train)\n",
    "    predict_y = clf.predict_proba(X_test)\n",
    "    log_loss_test = log_loss(y_test, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('reg_alpha = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)\n",
    "plt.plot(alpha,train_scores,label='Train Log Loss')\n",
    "plt.plot(alpha,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('reg_alpha')\n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"max_depth\": sp_randint(2,5),\n",
    "              \"learning_rate\":uniform(0,0.2),\n",
    "              \"n_estimators\":sp_randint(200,350),\n",
    "              \"min_child_weight\": sp_randint(2, 8),\n",
    "              \"gamma\": uniform(0,4),\n",
    "              \"subsample\":uniform(0.7,0.3),\n",
    "              \"colsample_bytree\": uniform(0.7,0.3),\n",
    "              \"reg_alpha\":uniform(100,300),\n",
    "              \"reg_lambda\":uniform(100,300)}\n",
    "\n",
    "model_rs_xgb = RandomizedSearchCV(xgb.XGBClassifier(n_jobs=-1,random_state=25), param_distributions=param_dist,\n",
    "                                   n_iter=30,scoring='neg_log_loss',cv=5,n_jobs=-1)\n",
    "model_rs_xgb.fit(X_train,y_train)\n",
    "pickle.dump(model_rs_xgb,open('model_rs_xgb.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_rs_xgb.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['n_estimators'])\n",
    "    dict_score.append(i[0]['max_depth'])\n",
    "    dict_score.append(i[0]['subsample'])\n",
    "    dict_score.append(i[0]['min_child_weight'])\n",
    "    dict_score.append(i[0]['learning_rate'])\n",
    "    dict_score.append(i[0]['reg_alpha'])\n",
    "    dict_score.append(i[0]['reg_lambda'])\n",
    "    dict_score.append(i[0]['gamma'])\n",
    "    dict_score.append(i[0]['colsample_bytree'])\n",
    "    dict_score.append(-i[1])\n",
    "    dict_score.append((np.abs(i[2]).std()))\n",
    "    dict_score.append(-model_rs_xgb.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df = pd.DataFrame(dict_scores,columns=['n_estimators','depth','subsample','min_child_weight',\n",
    "                                               'learning_rate','reg_alpha','reg_lambda','gamma',\n",
    "                                               'colsample_bytree','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.sort_values('Test_score').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(max_depth=4,learning_rate=0.078998,n_estimators=312,\n",
    "                        min_child_weight=7,subsample=0.862849,\n",
    "                        reg_alpha=151.329530,reg_lambda=368.527334,\n",
    "                        colsample_bytree=0.889555,gamma=2.475153,n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "predict_y = clf.predict_proba(X_test)\n",
    "print(\"The test log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Tf-Idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[0:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n",
    "\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3 = dfnlp[['id','question1','question2']]\n",
    "duplicate = dfnlp.is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so for Tf-Idf Features i am combining question1 and question2, then getting Tf-Idf for for Train and transforming test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.fillna(' ')\n",
    "df4 = pd.DataFrame()\n",
    "df4['Text'] = df3.question1 + ' ' + df3.question2\n",
    "df4['id'] = df3.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining question1 and question2, then getting Tf-Idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['id']=df1['id']\n",
    "df4['id']=df1['id']\n",
    "df5  = df1.merge(df2, on='id',how='left')\n",
    "final  = df5.merge(df4, on='id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf,X_test_tf, y_train_tf, y_test_tf = train_test_split(final,duplicate, stratify=y_true, test_size=0.3,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,3),max_features=200000,min_df=0.000032)\n",
    "train_tfidf = tfidf_vect.fit_transform(X_train_tf.Text)\n",
    "test_tfidf = tfidf_vect.transform(X_test_tf.Text)\n",
    "print('No of Tfidf features',len(tfidf_vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf = X_train_tf.drop('Text',axis=1)\n",
    "X_test_tf = X_test_tf.drop('Text',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_train1 = hstack((X_train_tf.values,train_tfidf))\n",
    "X_test1 = hstack((X_test_tf.values,test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler(with_mean=False)\n",
    "X_train_sc = scale.fit_transform(X_train1)\n",
    "X_test_sc = scale.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train_sc, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train_sc, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "alpha = np.random.uniform(0.05,0.5,14)\n",
    "alpha = np.round(alpha,4)\n",
    "alpha.sort()\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train_sc, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train_sc, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test_sc)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it was giving some good scores but it seems to be some overfitting in this.  \n",
    "i think it may be because of feature scaling for all the data including tfidf values so i tried without feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train1, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test1)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train1, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train1)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test1)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i decresed overfittig but bias increased.\n",
    "Tought like i will scale features otherthan Tf-Idf and Tf-Idf was already coming with l2 normalization. so tried with this format below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "X_train_some = scale.fit_transform(X_train_tf)\n",
    "X_test_some = scale.transform(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_train2 = hstack((X_train_some,train_tfidf))\n",
    "X_test2 = hstack((X_test_some,test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train2, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test2)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train2, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train2)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test2)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it seems to be good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "alpha = np.random.uniform(0.000002,0.00003,14)\n",
    "alpha = np.round(alpha,8)\n",
    "alpha.sort()\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train2, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test2)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train2, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train2)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test2)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM with Hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='hinge', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train2, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test2)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train2, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train2)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test2)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "alpha = np.random.uniform(0.000002,0.00003,14)\n",
    "alpha = np.round(alpha,8)\n",
    "alpha.sort()\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='hinge', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train2, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test2)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train2, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train2)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test2)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With some others features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n",
    "\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(sent):\n",
    "    sent  = str(sent)\n",
    "    if sent == None:\n",
    "        return ' '\n",
    "    if sent==np.nan:\n",
    "        return ' '\n",
    "    if sent == 'NaN':\n",
    "        return ' '\n",
    "    z = [i for i in sent.split() if i not in STOP_WORDS]\n",
    "    return ' '.join(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnlp['question1'] = dfnlp.question1.apply(remove_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnlp['question2'] = dfnlp.question2.apply(remove_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_input_file=\"glove.840B.300d.txt\", word2vec_output_file=\"glove_vectors.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmd(s1, s2,model):\n",
    "    s1 = str(s1)\n",
    "    s2 = str(s2)\n",
    "    s1 = s1.split()\n",
    "    s2 = s2.split()\n",
    "    return model.wmdistance(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://proceedings.mlr.press/v37/kusnerb15.pdf i read about word mover distance and after that i calculated some distances from avg word vectors as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnlp['Word_Mover_Dist'] = dfnlp.apply(lambda x: wmd(x['question1'], x['question2'],glove_model), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the avg-w2v for each sentence/review is stored in this list\n",
    "def avg_w2v(list_of_sent,model,d):\n",
    "    '''\n",
    "    Returns average of word vectors for\n",
    "    each sentance with dimension of model given\n",
    "    '''\n",
    "    sent_vectors = []\n",
    "    for sent in list_of_sent: # for each review/sentence\n",
    "        doc = [word for word in sent if word in model.wv.vocab]\n",
    "        if doc:\n",
    "            sent_vec = np.mean(model.wv[doc],axis=0)\n",
    "        else:\n",
    "            sent_vec = np.zeros(d)\n",
    "        sent_vectors.append(sent_vec)\n",
    "    return sent_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting into lists\n",
    "list_of_question1=[]\n",
    "for sent in dfnlp.question1.values:\n",
    "    list_of_question1.append(sent.split())\n",
    "list_of_question2=[]\n",
    "for sent in dfnlp.question2.values:\n",
    "    list_of_question2.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg word 2 vec\n",
    "avgw2v_q1 = avg_w2v(list_of_question1,glove_model,300)\n",
    "avgw2v_q2 = avg_w2v(list_of_question2,glove_model,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting as df\n",
    "df_avgw2v = pd.DataFrame()\n",
    "df_avgw2v['q1_vec'] = list(avgw2v_q1)\n",
    "df_avgw2v['q2_vec'] = list(avgw2v_q2)\n",
    "df_q1 = pd.DataFrame(df_avgw2v.q1_vec.values.tolist())\n",
    "df_q2 = pd.DataFrame(df_avgw2v.q2_vec.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing soma distances and calculating\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import cosine, cityblock,canberra, euclidean, minkowski\n",
    "dfnlp['dist_cosine'] = [cosine(x, y) for (x, y) in zip(avgw2v_q1,avgw2v_q2)]\n",
    "dfnlp['dist_cityblock'] = [cityblock(x, y) for (x, y) in zip(avgw2v_q1,avgw2v_q2)]\n",
    "dfnlp['dist_canberra'] = [canberra(x, y) for (x, y) in zip(avgw2v_q1,avgw2v_q2)]\n",
    "dfnlp['dist_euclidean'] = [euclidean(x, y) for (x, y) in zip(avgw2v_q1,avgw2v_q2)]\n",
    "dfnlp['dist_minkowski'] = [minkowski(x, y) for (x, y) in zip(avgw2v_q1,avgw2v_q2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling na values with 0  for cosine distance\n",
    "dfnlp.dist_cosine = dfnlp.dist_cosine.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merzing all df\n",
    "df_q1.reset_index(inplace=True)\n",
    "df_q2.reset_index(inplace=True)\n",
    "df_q1['index'] = df_q2['index']\n",
    "df_avgw2v_final = df_q1.merge(df_q2, on='index',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for final df\n",
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##merging all \n",
    "df1.id = df_avgw2v.index\n",
    "df2.id = df_avgw2v.index\n",
    "df_temp = df1.merge(df2,on='id',how='left')\n",
    "df_final = df_temp.merge(df_avgw2v_final,left_on='id',right_on='index',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to disk\n",
    "df_final.to_csv('df_final_avg.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('df_final_avg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## max no after inf is 13.45 so imputed infinity with 30\n",
    "df_final.Word_Mover_Dist = df_final.Word_Mover_Dist.apply(lambda x: 30 if x == np.inf else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set of values\n",
    "np.sort(list(set(df_final.Word_Mover_Dist.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df_final.shape[0]\n",
    "sns.pairplot(df_final[['Word_Mover_Dist', 'dist_cosine', 'dist_cityblock', \n",
    "                       'dist_canberra','dist_euclidean', 'is_duplicate']][0:n], \n",
    "             hue='is_duplicate', vars=['Word_Mover_Dist', 'dist_cosine', 'dist_cityblock', 'dist_canberra','dist_euclidean'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##removing dependent varible\n",
    "duplicate = df_final.is_duplicate\n",
    "df_final = df_final.drop(['id','is_duplicate','index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train,X_test, y_train, y_test = train_test_split(df_final,duplicate, stratify=duplicate, test_size=0.3,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*10, \"Distribution of output variable in train data\", \"-\"*10)\n",
    "train_distr = Counter(y_train)\n",
    "train_len = len(y_train)\n",
    "print(\"Class 0: \",int(train_distr[0])/train_len,\"Class 1: \", int(train_distr[1])/train_len)\n",
    "print(\"-\"*10, \"Distribution of output variable in train data\", \"-\"*10)\n",
    "test_distr = Counter(y_test)\n",
    "test_len = len(y_test)\n",
    "print(\"Class 0: \",int(test_distr[1])/test_len, \"Class 1: \",int(test_distr[1])/test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_col = ['cwc_min', 'cwc_max', 'csc_min', 'csc_max', 'ctc_min', 'ctc_max', 'last_word_eq', \n",
    "             'first_word_eq', 'abs_len_diff', 'mean_len', 'token_set_ratio', 'token_sort_ratio',\n",
    "             'fuzz_ratio', 'fuzz_partial_ratio', 'longest_substr_ratio', 'Word_Mover_Dist',\n",
    "             'dist_cosine', 'dist_cityblock', 'dist_canberra', 'dist_euclidean', \n",
    "             'dist_minkowski', 'freq_qid1', 'freq_qid2', 'q1len', 'q2len', 'q1_n_words', \n",
    "             'q2_n_words', 'word_Common', 'word_Total', 'word_share', 'freq_q1+q2', 'freq_q1-q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scale = X_train[scale_col]\n",
    "X_test_scale = X_test[scale_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = X_train.drop(scale_col,axis=1)\n",
    "X_test_w2v = X_test.drop(scale_col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "X_train_sc = scale.fit_transform(X_train_scale)\n",
    "X_test_sc = scale.transform(X_test_scale)\n",
    "X_train_sc = pd.DataFrame(X_train_sc,columns=X_train_scale.columns)\n",
    "X_test_sc = pd.DataFrame(X_test_sc,columns=X_test_scale.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final train and test vectors after scaling of normal features \n",
    "X_train_fi = pd.DataFrame(np.hstack((X_train_sc.values,X_train_w2v.values)),columns=df_final.columns)\n",
    "X_test_fi = pd.DataFrame(np.hstack((X_test_sc.values,X_test_w2v.values)),columns=df_final.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train_fi, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test_fi)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train_fi, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train_fi)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test_fi)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "alpha = np.random.uniform(0.0005,0.005,14)\n",
    "alpha = np.round(alpha,6)\n",
    "alpha.sort()\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train_fi, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test_fi)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train_fi, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train_fi)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test_fi)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=’hinge’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=’optimal’, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, …])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "#-------------------------------\n",
    "# video link: \n",
    "#------------------------------\n",
    "\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='hinge', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train_fi, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_test_fi)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train_fi, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(X_train_fi)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y,eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(X_test_fi)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y,eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [100,150,200,300,400,600,800]\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "for i in estimators:\n",
    "    clf = xgb.XGBClassifier(max_depth=3,learning_rate=0.1,n_estimators=i,n_jobs=-1)\n",
    "    clf.fit(X_train_fi,y_train)\n",
    "    predict_y = clf.predict_proba(X_train_fi)\n",
    "    log_loss_train = log_loss(y_train, predict_y, eps=1e-15)\n",
    "    train_scores.append(log_loss_train)\n",
    "    predict_y = clf.predict_proba(X_test_fi)\n",
    "    log_loss_test = log_loss(y_test, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('estimators = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)\n",
    "#plt.plot(estimators,train_scores,label='Train Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(max_depth=3,learning_rate=0.12,n_estimators=600,\n",
    "                        min_child_weight=5,\n",
    "                        reg_alpha=150,reg_lambda=350,n_jobs=-1)\n",
    "clf.fit(X_train_fi,y_train)\n",
    "predict_y = clf.predict_proba(X_test_fi)\n",
    "print(\"The test log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(X_train_fi.columns)[np.argsort(clf.feature_importances_)[::-1]][0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained XGBoost on data dropping avg word vectors with below columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scale.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [100,150,200,300,400,600,800]\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "for i in estimators:\n",
    "    clf = xgb.XGBClassifier(max_depth=3,learning_rate=0.1,n_estimators=i,n_jobs=-1)\n",
    "    clf.fit(X_train_scale,y_train)\n",
    "    predict_y = clf.predict_proba(X_train_scale)\n",
    "    log_loss_train = log_loss(y_train, predict_y, eps=1e-15)\n",
    "    train_scores.append(log_loss_train)\n",
    "    predict_y = clf.predict_proba(X_test_scale)\n",
    "    log_loss_test = log_loss(y_test, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('estimators = ',i,'Train Log Loss ',log_loss_train,'Test Log Loss ',log_loss_test)\n",
    "plt.plot(estimators,train_scores,label='Train Log Loss')\n",
    "plt.plot(estimators,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('estimators')\n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"max_depth\": sp_randint(2,5),\n",
    "              \"learning_rate\":uniform(0,0.25),\n",
    "              \"n_estimators\":sp_randint(300,600),\n",
    "              \"min_child_weight\": sp_randint(2, 8),\n",
    "              \"gamma\": uniform(0,4),\n",
    "              \"subsample\":uniform(0.7,0.3),\n",
    "              \"colsample_bytree\": uniform(0.7,0.3),\n",
    "              \"reg_alpha\":uniform(100,300),\n",
    "              \"reg_lambda\":uniform(100,300)}\n",
    "\n",
    "model_rs_xgb1 = RandomizedSearchCV(xgb.XGBClassifier(n_jobs=-1,random_state=25), param_distributions=param_dist,\n",
    "                                   n_iter=30,scoring='neg_log_loss',cv=5,n_jobs=-1)\n",
    "model_rs_xgb1.fit(X_train_scale,y_train)\n",
    "pickle.dump(model_rs_xgb1,open('model_rs_xgb1.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_rs_xgb1.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['n_estimators'])\n",
    "    dict_score.append(i[0]['max_depth'])\n",
    "    dict_score.append(i[0]['subsample'])\n",
    "    dict_score.append(i[0]['min_child_weight'])\n",
    "    dict_score.append(i[0]['learning_rate'])\n",
    "    dict_score.append(i[0]['reg_alpha'])\n",
    "    dict_score.append(i[0]['reg_lambda'])\n",
    "    dict_score.append(i[0]['gamma'])\n",
    "    dict_score.append(i[0]['colsample_bytree'])\n",
    "    dict_score.append(-i[1])\n",
    "    dict_score.append((np.abs(i[2]).std()))\n",
    "    dict_score.append(-model_rs_xgb1.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df = pd.DataFrame(dict_scores,columns=['n_estimators','depth','subsample','min_child_weight',\n",
    "                                               'learning_rate','reg_alpha','reg_lambda','gamma',\n",
    "                                               'colsample_bytree','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.sort_values('Test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in my view 2nd line (28) is beeter score than forst beacuse of train test scores and test standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score params')\n",
    "scores_df.loc[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(max_depth=4,learning_rate=0.131131,n_estimators=500,\n",
    "                        min_child_weight=6,\n",
    "                        reg_alpha=119.704012,reg_lambda=115.715236,\n",
    "                        gamma=3.768808,colsample_bytree=0.911753,n_jobs=-1)\n",
    "clf.fit(X_train_scale,y_train)\n",
    "predict_y = clf.predict_proba(X_test_scale)\n",
    "print(\"The test log loss is:\",log_loss(y_test, predict_y, eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
