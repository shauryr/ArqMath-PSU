{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Result Notebook\n",
    "\n",
    "Steps : \n",
    "1. Search Full questions+title in *arq_ans_ques* index\n",
    "2. Save these results as Baseline-run\n",
    "\n",
    "----\n",
    "1. Now again - Search Full questions+title in *arq_ans_ques* index\n",
    "2. Rerank them using BERT - save results\n",
    "3. Merge Baseline-run and Rerank-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import jsonlines\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from elasticsearch import Elasticsearch\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import gc\n",
    "import math\n",
    "import torch\n",
    "from transformers import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ques_path = '/data/szr207/dataset/ArqMath/jsons/questions/all.ques.jsonl'\n",
    "ans_path = '/data/szr207/dataset/ArqMath/jsons/answers/all.ans.jsonl'\n",
    "topic_file_path = \"/data/szr207/dataset/ArqMath/Task1/Topics/Topics_V2.0.xml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8a41fc817c4e2d94f0d7f185361141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=98.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.1 Finding value of $c$ such that the range of the rational function $f(x) = \\frac{ ...\n",
      "A.3 Approximation to $\\sqrt{5}$ correct to an exactitude of $10^{-10}$. I am attempt ...\n",
      "A.4 How to compute this combinatoric sum?. I have the sum  $$\\sum_{k=0}^{n} \\binom{n ...\n",
      "A.5 A family has two children. Given that one of the children is a boy, what is the  ...\n",
      "A.7 Finding out the remainder of $\\frac{11^\\text{10}-1}{100}$ using modulus.    If $ ...\n",
      "A.8 finding value of $\\lim_{n\\rightarrow \\infty}\\sqrt[n]{\\frac{(27)^n(n!)^3}{(3n)!}} ...\n",
      "A.9 Simplifying this series. I need to write the series   $$\\sum_{n=0}^N nx^n$$   in ...\n",
      "A.10 Find the values of a>0 for which the improper integral $\\int_{0}^{\\infty}\\frac{\\ ...\n",
      "A.11 What's the cross product in 2 dimensions?. The math book i'm using states that t ...\n",
      "A.12 Finding the roots of a complex number. I was solving practice problems for my up ...\n",
      "A.13 How to simplify expression $\\int_a^b f(x)dx+\\int_{f(a)}^{f(b)} f^{-1}(x)dx \\ ?$. ...\n",
      "A.14 Help solving first-order differential equation. I have first-order differential  ...\n",
      "A.15 Derive the sum of $\\sum_{i=1}^n ix^{i-1}$. For the series      $$1 + 2x + 3x^2 + ...\n",
      "A.16 Finding $ \\int_0^1\\frac{\\ln(1+x)\\ln(1-x)}{1+x}dx$.    Calculate   $$\\int_0^1\\fra ...\n",
      "A.17 Calculate $\\int _{x=0}^{\\infty} \\frac{\\sin(x)}{x}$ with the function $\\frac{e^{i ...\n",
      "A.18 Evaluate $\\lim_{n \\rightarrow \\infty } \\frac {[(n+1)(n+2)\\cdots(n+n)]^{1/n}}{n}$ ...\n",
      "A.19 Greatest common factor of $ p^4-1$. I was asked to find the greatest common fact ...\n",
      "A.20 Calculate all $n \\in \\Bbb N \\setminus \\{41\\}$ such that $\\phi(n)=40$?.    I'm lo ...\n",
      "A.21 Finding the last two digits of $9^{9^{9^{…{^9}}}}$ (nine 9s). I'm continuing on  ...\n",
      "A.23 How do i find the lcm. Qn: If the product of two integers is  $2^7 \\cdot 3^8 \\cd ...\n",
      "A.24 Is this the only way to evaluate $\\sqrt{2i-1}?$. work out the $\\sqrt{2i-1}?$  $2 ...\n",
      "A.26 How to solve an indefinite integral using the Taylor series?. I am trying to sho ...\n",
      "A.27 What is the value of $e^{3i \\pi /2}$?. When solving for the value, we know that  ...\n",
      "A.28 If $\\sin(18^\\circ)=\\frac{a + \\sqrt{b}}{c}$, then what is $a+b+c$?. If $\\sin(18)= ...\n",
      "A.29 Dividing Complex Numbers by Infinity. My PreCalculus teacher recently reviewed t ...\n",
      "A.30 Find $a^3+b^3+c^3-3abc$ (binomial theorem).    $$a=\\sum_{n=0}^\\infty\\frac{x^{3n} ...\n",
      "A.32 Are definitions axioms?. I just want to ask a very elementary question.  When we ...\n",
      "A.33 Physical meaning and significance of third derivative of a function. Given a phy ...\n",
      "A.35 When does a function NOT have an antiderivative?. I know this question may sound ...\n",
      "A.36 Proof by contradiction, status of initial assumption after the proof is complete ...\n",
      "A.37 Non trivial examples of $f\\circ g = g \\circ f$ but $f^{-1} \\neq g$ and $f\\neq\\ma ...\n",
      "A.38 Uses of Axiom of Choice. I am a first-year maths student but I occasionally drif ...\n",
      "A.39 How to know which value is bigger?. Which is bigger between $2018^{2019}$ or $\\  ...\n",
      "A.40 What is the meaning of the term \"linear\". $a_1x_1+a_2x_2+a_3x_3+...+a_nx_n=$ is  ...\n",
      "A.41 Confusion in how to find number of onto functions if two sets are given. In the  ...\n",
      "A.42 What is a simple, physical situation where complex numbers emerge naturally?. I' ...\n",
      "A.43 Prove $\\sum_{n\\geq1}\\frac1{n^2+1}=\\frac{\\pi\\coth\\pi-1}2$. I am trying to prove   ...\n",
      "A.44 For $A,B \\in \\mathscr{M}_{2\\times2}(\\mathbb{Q}) $ of finite order, show that $AB ...\n",
      "A.45 How to prove that {$\\sin(x) , \\sin(2x) , \\sin(3x) ,...,\\sin(nx)$} is independent ...\n",
      "A.47 Prove that for a given prime $p$ and each $0 < r < p-1$, there exists a $q$ such ...\n",
      "A.48 Hints for showing that if $x,y \\geq 0$, then $(x+y)^k \\geq x^k + y^k$ for all $k ...\n",
      "A.49 Is there a simple combinatoric interpretation of this identity?. I came across a ...\n",
      "A.50 Divergent series $\\sum{\\frac{1}{n^{2+\\cos{n}}}}$. Bonjour.  Show that  $$\\sum{\\f ...\n",
      "A.51 Sum of series having binomial coefficients. Prove that $\\displaystyle \\sum_{r=0} ...\n",
      "A.52 Prove $\\forall n\\in\\mathbb{N}$, $\\exists m\\in\\mathbb{N}$ s.t. $m>n$ and $m$ is p ...\n",
      "A.53 Show that one-sided inverse of a square matrix is a true inverse. We know that f ...\n",
      "A.54 By using a diagonal argument, show that the powerset $P(N) = (S|S ⊆ N)$ is uncou ...\n",
      "A.55 $\\frac{1}{\\sqrt{-1}}=\\sqrt{-1}$?. I have trouble to comprehend what my mistake i ...\n",
      "A.56 A curious logical formula involving prime numbers. Let $S$ be a nonempty set of  ...\n",
      "A.58 Prove that $3\\arcsin \\frac{1}{4} + \\arccos \\frac {11}{16} = \\frac {\\pi}{2}$. Can ...\n",
      "A.59 Multiple proofs of $\\sum_{d|n}{\\phi(d)}=n$. I am looking for multiple proofs of  ...\n",
      "A.60 Limiting value of a sequence when n tends to infinity. Q) Let, $a_{n} \\;=\\; \\lef ...\n",
      "A.61 There exists $i, j \\in \\mathbb{N}$ such that $n=3i+5j$ for $n\\ge 8$.    Prove th ...\n",
      "A.62 Prove that the cardinality of the set of rational numbers and the set of integer ...\n",
      "A.63 $\\gcd$ and $\\text{lcm}$ of more than $2$ positive integers. For any two positive ...\n",
      "A.65 How can we show that $e^{-2\\lambda t}\\lambda^2\\le\\frac1{e^2t^2}$ for all $\\lambd ...\n",
      "A.66 if $x,h \\in \\mathbb{R}^d$ and $A \\in \\mathbb{R}^{d\\times d}$ is it possible to j ...\n",
      "A.67 Combination of matrixes. If A is a $k\\times k$ matrix,B is a $k\\times l$ matrix  ...\n",
      "A.68 Prove $a^n+1$ is divisible by $a + 1$ if $n$ is odd. Prove $a^n+1$ is divisible  ...\n",
      "A.69 Induction with two variable parameters. So I was assigned this homework problem: ...\n",
      "A.72 Is it possible that $\\mathcal{X} = \\mathcal{Y}$, yet $\\mathcal{X} \\in \\mathcal{Y ...\n",
      "A.74 Show that the image of the function $f:(0,\\infty)\\rightarrow \\mathbb{R}$, $f(x)= ...\n",
      "A.75 Prove that for each integer $m$, $ \\lim_{u\\to \\infty} \\frac{u^m}{e^u} = 0 $. I'm ...\n",
      "A.77 Show that the relation $(- 1) (- 1) = 1$ is a consequence of the distributive la ...\n",
      "A.79 Inequality with complex exponential. Rudin in Real and Complex Analysis uses thi ...\n",
      "A.80 Why does this proof that the set of all finite subsets of N is a countable set n ...\n",
      "A.83 Is the sequence of sums of inverse of natural numbers bounded?. I'm reading thro ...\n",
      "A.85 Expected number of steps for a bug to reach position $N$. A bug starts at time $ ...\n",
      "A.86 Is it true that $\\sum_{k=0}^{n}k\\cdot \\left(\\begin{array}{l}{n}\\\\{k}\\end{array}\\ ...\n",
      "A.87 Is it true that $\\forall n \\in \\Bbb{N} : (\\sum_{i=1}^{n} a_{i} ) (\\sum_{i=1}^{n} ...\n",
      "A.88 Is the polynomial $x^4+10x^2+1$ reducible over $\\mathbb{Z}[x]$?. Is the polynomi ...\n",
      "A.89 Parametrization of pythagorean-like equation. Is there any known complete parame ...\n",
      "A.90 Question on the definition of an Inverse matrix. By definition, if $A$ is a $ n  ...\n",
      "A.93 Characteristic Polynomial $AB =$ characteristic polynomial $ BA$?. Let $A,B$ mat ...\n",
      "A.96 Let $\\sum_i a_i$ be a convergent sum with positive $a_i$. Does $\\sum_i \\frac{a_i ...\n",
      "A.98 If $R:S^{1}\\rightarrow S^{1}$ is a irrational rotation, $\\{R^{n}([x])\\}$ is dens ...\n",
      "A.99 Rationals can be the set of continuity of a function?. Most of the functions tha ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Topic:\n",
    "    \"\"\"\n",
    "    This class shows a topic for task 1. Each topic has an topic_id which is str, a title and question which\n",
    "    is the question body and a list of tags.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, topic_id, title, question, tags):\n",
    "        self.topic_id = topic_id\n",
    "        self.title = title\n",
    "        self.question = question\n",
    "        self.lst_tags = tags\n",
    "\n",
    "\n",
    "class TopicReader:\n",
    "    \"\"\"\n",
    "    This class takes in the topic file path and read all the topics into a map. The key in this map is the topic id\n",
    "    and the values are Topic which has 4 attributes: id, title, question and list of tags for each topic.\n",
    "\n",
    "    To see each topic, use the get_topic method, which takes the topic id and return the topic in Topic object and\n",
    "    you have access to the 4 attributes mentioned above.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, topic_file_path):\n",
    "        self.__map_topics = self.__read_topics(topic_file_path)\n",
    "\n",
    "    def __read_topics(self, topic_file_path):\n",
    "        map_topics = {}\n",
    "        tree = ET.parse(topic_file_path)\n",
    "        root = tree.getroot()\n",
    "        for child in root:\n",
    "            topic_id = child.attrib['number']\n",
    "            title = child[0].text\n",
    "            question = child[1].text\n",
    "            lst_tag = child[2].text.split(\",\")\n",
    "            map_topics[topic_id] = Topic(topic_id, title, question, lst_tag)\n",
    "        return map_topics\n",
    "\n",
    "    def get_topic(self, topic_id):\n",
    "        if topic_id in self.__map_topics:\n",
    "            return self.__map_topics[topic_id]\n",
    "        return None\n",
    "\n",
    "def remove_stop(query):\n",
    "    with open('englishST.txt') as f:\n",
    "        all_stopwords = f.readlines()\n",
    "    # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "    all_stopwords = [x.strip() for x in all_stopwords] \n",
    "    text_tokens = query.split(' ')\n",
    "    query = [word for word in text_tokens if not word in all_stopwords]\n",
    "    query = ' '.join(query)\n",
    "    return query\n",
    "\n",
    "def remove_punct(my_str):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    # To take input from the user\n",
    "    # my_str = input(\"Enter a string: \")\n",
    "\n",
    "    # remove punctuation from the string\n",
    "    no_punct = \"\"\n",
    "    for char in my_str:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "\n",
    "    # display the unpunctuated string\n",
    "    return no_punct\n",
    "\n",
    "es = Elasticsearch(['http://csxindex05:9200/'], verify_certs=True)\n",
    "queries = []\n",
    "#\"In this example, the title and the question body of topic with id A.1 is printed.\"\n",
    "topic_reader = TopicReader(topic_file_path)\n",
    "dict_q_a = defaultdict(list)\n",
    "\n",
    "topic_list = []\n",
    "with open('../runs/qrel_task1', 'r') as eval_file:\n",
    "    for _,line in enumerate(eval_file):\n",
    "        topic_list.append(line.split('\\t')[0])\n",
    "\n",
    "topic_list = list(set(topic_list))\n",
    "\n",
    "list_p = []\n",
    "with open('../runs/qrel_task1', 'r') as eval_file:\n",
    "    for _,line in enumerate(eval_file):\n",
    "        list_p.append(line.split('\\t')[2])\n",
    "\n",
    "list_p = list(set(list_p))\n",
    "\n",
    "with open('tf.psu-task1-prim.mlt-auto-both-A.tsv', 'w') as eval_file:\n",
    "    for topic_id in tqdm(topic_reader._TopicReader__map_topics):\n",
    "        if topic_id in topic_list:\n",
    "            title = re.sub('<[^<]+?>', '', topic_reader.get_topic(topic_id).title)\n",
    "            body = topic_reader.get_topic(topic_id).question\n",
    "            body_pro = re.sub('<[^<]+?>', '', body)\n",
    "            query = title + '. ' + body_pro\n",
    "            queries.append(query)\n",
    "    #         query = query.lower()\n",
    "    #         query = remove_stop(query)\n",
    "            print(topic_id, query[:80], '...')\n",
    "            body = {\n",
    "                \"size\": 1000,\n",
    "                 \"query\": {\n",
    "                       \"more_like_this\" : {\n",
    "                    \"fields\" : [\"body\"],\n",
    "                    \"like\" : query,\n",
    "                }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            res = es.search(index=\"arq_ans_ques\", body=body, request_timeout=1000)\n",
    "\n",
    "            for result in res['hits']['hits']:\n",
    "                if str(result['_source']['post_id']) in list_p:\n",
    "                    dict_q_a[topic_id].append(result['_source']['post_id'])\n",
    "\n",
    "            count = 1\n",
    "            for result in res['hits']['hits']:\n",
    "                if str(result['_source']['post_id']) in list_p:\n",
    "                    eval_file.write(topic_id+'\\t'+ '1\\t' +str(result['_source']['post_id'])+'\\t'+str(count)+'\\t'+ str(result['_score'])+'\\t'+ 'mlt_base'+'\\n')\n",
    "                    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f292d12baf8648488cf5468b93d5c2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f63ee4f9f8e4c26a5687659146469e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33cc31c4c1f42e6af6ffa9b80eea3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1435643.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dict_ques = {}\n",
    "dict_ans = {}\n",
    "dict_aid_body = {}\n",
    "\n",
    "with jsonlines.open(os.path.join(ques_path)) as reader:\n",
    "        for obj in tqdm(reader):\n",
    "            dict_ques[obj['post_id']] = obj\n",
    "    \n",
    "with jsonlines.open(os.path.join(ans_path)) as reader:\n",
    "        for obj in tqdm(reader):\n",
    "            dict_ans[obj['post_id']] = obj\n",
    "\n",
    "for a_id in tqdm(list(dict_ans.keys())):\n",
    "    ans_body = re.sub('<[^<]+?>', '',  dict_ans[a_id]['body'])\n",
    "    qid = dict_ans[a_id]['parent_id']\n",
    "    ques_body = re.sub('<[^<]+?>', '',  dict_ques[qid]['body'])\n",
    "    ques_title = re.sub('<[^<]+?>', '',  dict_ques[qid]['title'])\n",
    "    dict_aid_body[a_id] = ques_title + '. ' + ques_body #+ '. ' + ans_body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReRanking using fine-tuned HF RoBERTa-Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model name 'shauryr/checkpoint-475000' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-japanese, bert-base-japanese-whole-word-masking, bert-base-japanese-char, bert-base-japanese-char-whole-word-masking, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased, bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum, openai-gpt, transfo-xl-wt103, gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2, ctrl, xlnet-base-cased, xlnet-large-cased, xlm-mlm-en-2048, xlm-mlm-ende-1024, xlm-mlm-enfr-1024, xlm-mlm-enro-1024, xlm-mlm-tlm-xnli15-1024, xlm-mlm-xnli15-1024, xlm-clm-enfr-1024, xlm-clm-ende-1024, xlm-mlm-17-1280, xlm-mlm-100-1280, roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector, distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-cased, distilbert-base-cased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased, distilbert-base-uncased-finetuned-sst-2-english, albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2, camembert-base, umberto-commoncrawl-cased-v1, umberto-wikipedia-uncased-v1, t5-small, t5-base, t5-large, t5-3b, t5-11b, xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german, flaubert-small-cased, flaubert-base-uncased, flaubert-base-cased, flaubert-large-cased, google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert/shauryr/checkpoint-475000/modelcard.json' was a path or url to a model card file named modelcard.json or a directory containing such a file but couldn't find any such file at this path or url.\n",
      "Creating an empty model card.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import *\n",
    "\n",
    "# feat_ext = pipeline(\"feature-extraction\", model=\"shauryr/checkpoint-4000000\", tokenizer='roberta-base', device=0) #our finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f264c712e22f40beaa094702d9fdc135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_emb = []\n",
    "for query in tqdm(queries):\n",
    "    ques_emb.append(np.mean(feat_ext(query)[0], axis=0))\n",
    "\n",
    "del feat_ext\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41abdaf20c8343c586cd03feda4ac53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=98.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dict_q_idx = {}\n",
    "count = 0\n",
    "for topic_id in tqdm(topic_reader._TopicReader__map_topics):\n",
    "    dict_q_idx[topic_id]=0\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_Tuple(tup):  \n",
    "    # reverse = None (Sorts in Ascending order)  \n",
    "    # key is set to sort using second element of  \n",
    "    # sublist lambda has been used  \n",
    "    tup.sort(key = lambda x: x[2])\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_str(tokenizer, body):\n",
    "    encoded = tokenizer.encode(body)[:510]\n",
    "    return tokenizer.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc53018a2c9448cf8e12e69d4898b1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=98.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model name 'shauryr/checkpoint-475000' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-japanese, bert-base-japanese-whole-word-masking, bert-base-japanese-char, bert-base-japanese-char-whole-word-masking, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased, bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum, openai-gpt, transfo-xl-wt103, gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2, ctrl, xlnet-base-cased, xlnet-large-cased, xlm-mlm-en-2048, xlm-mlm-ende-1024, xlm-mlm-enfr-1024, xlm-mlm-enro-1024, xlm-mlm-tlm-xnli15-1024, xlm-mlm-xnli15-1024, xlm-clm-enfr-1024, xlm-clm-ende-1024, xlm-mlm-17-1280, xlm-mlm-100-1280, roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector, distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-cased, distilbert-base-cased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased, distilbert-base-uncased-finetuned-sst-2-english, albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2, camembert-base, umberto-commoncrawl-cased-v1, umberto-wikipedia-uncased-v1, t5-small, t5-base, t5-large, t5-3b, t5-11b, xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german, flaubert-small-cased, flaubert-base-uncased, flaubert-base-cased, flaubert-large-cased, google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert/shauryr/checkpoint-475000/modelcard.json' was a path or url to a model card file named modelcard.json or a directory containing such a file but couldn't find any such file at this path or url.\n",
      "Creating an empty model card.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cb8029bf684d24afbb61eed4ba93d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=146.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2916472\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "count = 0\n",
    "for qid in tqdm(topic_reader._TopicReader__map_topics):\n",
    "    if qid in topic_list:\n",
    "        tup_postid_sim = []\n",
    "        feat_ext = pipeline(\"feature-extraction\", model=\"shauryr/checkpoint-475000\", tokenizer='roberta-base', device=0) #our finetuned model\n",
    "        for post_id in tqdm(dict_q_a[qid]):\n",
    "            try:\n",
    "                feat = feat_ext(dict_aid_body[int(post_id)])[0]\n",
    "                ans_emb = np.mean(feat, axis=0)\n",
    "                del feat\n",
    "                gc.collect()\n",
    "            except:\n",
    "                print(post_id)\n",
    "                continue\n",
    "            result = 1 - spatial.distance.cosine(ques_emb[dict_q_idx[qid]], ans_emb)\n",
    "\n",
    "            if math.isnan(result):\n",
    "                count+=1\n",
    "                print(qid, post_id, count)\n",
    "                continue\n",
    "            tup_postid_sim.append((qid,post_id,result))\n",
    "        try:\n",
    "            del feat_ext\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        except:\n",
    "            print(qid)\n",
    "            continue\n",
    "\n",
    "        result_list.append(Sort_Tuple(tup_postid_sim)[::-1][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf.psu-task1-prim.mlt.bert-auto-both-A.tsv', 'w') as eval_file:\n",
    "    for res in result_list:\n",
    "        count = 1\n",
    "        for tuples in res:\n",
    "            eval_file.write(tuples[0]+'\\t' + str(tuples[1]) +'\\t'+str(count)+'\\t'+ str(tuples[2])+'\\t'+ 'mlt_bert'+'\\n')\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "feat_ext = pipeline(\"feature-extraction\", model=\"/data/szr207/github/transformers/examples/language-modeling/output/checkpoint-3000000\", tokenizer='roberta-base', device=0) #our finetuned model\n",
    "tokenizer =  RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "count = 0\n",
    "for qid in tqdm(list(topic_reader._TopicReader__map_topics.keys())):\n",
    "    tup_postid_sim = []\n",
    "    for post_id in tqdm(dict_q_a[qid]):\n",
    "        try:\n",
    "            feat = feat_ext(reduce_str(tokenizer, dict_aid_body[int(post_id)]))[0]\n",
    "            ans_emb = np.mean(feat, axis=0)\n",
    "        except:\n",
    "            print('CUDA error: an illegal memory access was encountered', post_id)\n",
    "            break\n",
    "        result = 1 - spatial.distance.cosine(ques_emb[dict_q_idx[qid]], ans_emb)\n",
    "        \n",
    "        if math.isnan(result):\n",
    "            count+=1\n",
    "            print(qid, post_id, count)\n",
    "            break\n",
    "        tup_postid_sim.append((qid,post_id,result))\n",
    "#     try:\n",
    "#         del feat_ext\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "#     except:\n",
    "#         print(qid)\n",
    "#         break\n",
    "        \n",
    "    result_list.append(Sort_Tuple(tup_postid_sim)[::-1][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del feat_ext\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf.psu-task1-mlt.bert-auto-both-A.tsv', 'w') as eval_file:\n",
    "    for res in result_list:\n",
    "        count = 1\n",
    "        for tuples in res:\n",
    "#             eval_file.write(tuples[0]+'\\t'+ '1\\t' + str(tuples[1]) +'\\t'+str(count)+'\\t'+ str(tuples[2])+'\\t'+ 'mlt_bert'+'\\n')\n",
    "            eval_file.write(tuples[0]+'\\t' + str(tuples[1]) +'\\t'+str(count)+'\\t'+ str(tuples[2])+'\\t'+ 'mlt_bert'+'\\n')\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging BERT and TF-IDF using RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trectools import TrecRun, TrecEval, fusion\n",
    "\n",
    "runs_path = '/data/szr207/projects/ArqMath/'\n",
    "r1 = TrecRun(os.path.join(runs_path, \"tf.psu-task1-mlt.bert-auto-both-A.tsv\"))\n",
    "r2 = TrecRun(os.path.join(runs_path, \"tf.psu-task1-mlt.base-auto-both-A.tsv\"))\n",
    "\n",
    "# Easy way to create new baselines by fusing existing runs:\n",
    "fused_run = fusion.reciprocal_rank_fusion([r1,r2])\n",
    "\n",
    "# Save run to disk with all its topics\n",
    "fused_run.print_subset(\"tf.psu-task1-rrf.base.bert-auto-both-P.tsv\", topics=fused_run.topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tf.psu-task1-rrf.base.bert-auto-both-P.tsv', header=None , sep=\" \")\n",
    "df = df.drop(columns=1)\n",
    "df.to_csv('psu-task1-rrf.base.bert-auto-both-P.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!java -jar jtreceval-0.0.5-jar-with-dependencies.jar -m ndcg /data/szr207/dataset/ArqMath/Task1/Sample\\ Topics/qrel.V1.0.tsv es.mlt.final.finetune.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul  5 23:43:11 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:18:00.0 Off |                  N/A |\n",
      "| 27%   32C    P8    11W / 250W |   3097MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 49%   58C    P2   233W / 250W |   1438MiB / 11019MiB |     65%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "| 27%   38C    P8    20W / 250W |     11MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:AF:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8     6W / 250W |     11MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0    225899      C   ...a/szr207/conda/envs/faiss/bin/python3.7   709MiB |\n",
      "|    0    337741      C   /data/nud83/anaconda3/envs/py36/bin/python  2377MiB |\n",
      "|    1    225899      C   ...a/szr207/conda/envs/faiss/bin/python3.7  1451MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
