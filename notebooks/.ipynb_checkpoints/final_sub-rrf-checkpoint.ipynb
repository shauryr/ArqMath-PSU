{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Result Notebook\n",
    "\n",
    "Steps : \n",
    "1. Search Full questions+title in *arq_ans_ques* index\n",
    "2. Save these results as Baseline-run\n",
    "\n",
    "----\n",
    "1. Now again - Search Full questions+title in *arq_ans_ques* index\n",
    "2. Rerank them using BERT - save results\n",
    "3. Merge Baseline-run and Rerank-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import jsonlines\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from elasticsearch import Elasticsearch\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import gc\n",
    "import math\n",
    "import torch\n",
    "from transformers import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ques_path = '/data/szr207/dataset/ArqMath/jsons/questions/all.ques.jsonl'\n",
    "ans_path = '/data/szr207/dataset/ArqMath/jsons/answers/all.ans.jsonl'\n",
    "topic_file_path = \"/data/szr207/dataset/ArqMath/Task1/Topics/Topics_V2.0.xml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8a41fc817c4e2d94f0d7f185361141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=98.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.1 Finding value of $c$ such that the range of the rational function $f(x) = \\frac{ ...\n",
      "A.3 Approximation to $\\sqrt{5}$ correct to an exactitude of $10^{-10}$. I am attempt ...\n",
      "A.4 How to compute this combinatoric sum?. I have the sum  $$\\sum_{k=0}^{n} \\binom{n ...\n",
      "A.5 A family has two children. Given that one of the children is a boy, what is the  ...\n",
      "A.7 Finding out the remainder of $\\frac{11^\\text{10}-1}{100}$ using modulus.    If $ ...\n",
      "A.8 finding value of $\\lim_{n\\rightarrow \\infty}\\sqrt[n]{\\frac{(27)^n(n!)^3}{(3n)!}} ...\n",
      "A.9 Simplifying this series. I need to write the series   $$\\sum_{n=0}^N nx^n$$   in ...\n"
     ]
    }
   ],
   "source": [
    "class Topic:\n",
    "    \"\"\"\n",
    "    This class shows a topic for task 1. Each topic has an topic_id which is str, a title and question which\n",
    "    is the question body and a list of tags.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, topic_id, title, question, tags):\n",
    "        self.topic_id = topic_id\n",
    "        self.title = title\n",
    "        self.question = question\n",
    "        self.lst_tags = tags\n",
    "\n",
    "\n",
    "class TopicReader:\n",
    "    \"\"\"\n",
    "    This class takes in the topic file path and read all the topics into a map. The key in this map is the topic id\n",
    "    and the values are Topic which has 4 attributes: id, title, question and list of tags for each topic.\n",
    "\n",
    "    To see each topic, use the get_topic method, which takes the topic id and return the topic in Topic object and\n",
    "    you have access to the 4 attributes mentioned above.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, topic_file_path):\n",
    "        self.__map_topics = self.__read_topics(topic_file_path)\n",
    "\n",
    "    def __read_topics(self, topic_file_path):\n",
    "        map_topics = {}\n",
    "        tree = ET.parse(topic_file_path)\n",
    "        root = tree.getroot()\n",
    "        for child in root:\n",
    "            topic_id = child.attrib['number']\n",
    "            title = child[0].text\n",
    "            question = child[1].text\n",
    "            lst_tag = child[2].text.split(\",\")\n",
    "            map_topics[topic_id] = Topic(topic_id, title, question, lst_tag)\n",
    "        return map_topics\n",
    "\n",
    "    def get_topic(self, topic_id):\n",
    "        if topic_id in self.__map_topics:\n",
    "            return self.__map_topics[topic_id]\n",
    "        return None\n",
    "\n",
    "def remove_stop(query):\n",
    "    with open('englishST.txt') as f:\n",
    "        all_stopwords = f.readlines()\n",
    "    # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "    all_stopwords = [x.strip() for x in all_stopwords] \n",
    "    text_tokens = query.split(' ')\n",
    "    query = [word for word in text_tokens if not word in all_stopwords]\n",
    "    query = ' '.join(query)\n",
    "    return query\n",
    "\n",
    "def remove_punct(my_str):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    # To take input from the user\n",
    "    # my_str = input(\"Enter a string: \")\n",
    "\n",
    "    # remove punctuation from the string\n",
    "    no_punct = \"\"\n",
    "    for char in my_str:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "\n",
    "    # display the unpunctuated string\n",
    "    return no_punct\n",
    "\n",
    "es = Elasticsearch(['http://csxindex05:9200/'], verify_certs=True)\n",
    "queries = []\n",
    "#\"In this example, the title and the question body of topic with id A.1 is printed.\"\n",
    "topic_reader = TopicReader(topic_file_path)\n",
    "dict_q_a = defaultdict(list)\n",
    "\n",
    "topic_list = []\n",
    "with open('../runs/qrel_task1', 'r') as eval_file:\n",
    "    for _,line in enumerate(eval_file):\n",
    "        topic_list.append(line.split('\\t')[0])\n",
    "\n",
    "topic_list = list(set(topic_list))\n",
    "\n",
    "list_p = []\n",
    "with open('../runs/qrel_task1', 'r') as eval_file:\n",
    "    for _,line in enumerate(eval_file):\n",
    "        list_p.append(line.split('\\t')[2])\n",
    "\n",
    "list_p = list(set(list_p))\n",
    "\n",
    "with open('tf.psu-task1-prim.mlt-auto-both-A.tsv', 'w') as eval_file:\n",
    "    for topic_id in tqdm(topic_reader._TopicReader__map_topics):\n",
    "        if topic_id in topic_list:\n",
    "            title = re.sub('<[^<]+?>', '', topic_reader.get_topic(topic_id).title)\n",
    "            body = topic_reader.get_topic(topic_id).question\n",
    "            body_pro = re.sub('<[^<]+?>', '', body)\n",
    "            query = title + '. ' + body_pro\n",
    "            queries.append(query)\n",
    "    #         query = query.lower()\n",
    "    #         query = remove_stop(query)\n",
    "            print(topic_id, query[:80], '...')\n",
    "            body = {\n",
    "                \"size\": 1000,\n",
    "                 \"query\": {\n",
    "                       \"more_like_this\" : {\n",
    "                    \"fields\" : [\"body\"],\n",
    "                    \"like\" : query,\n",
    "                }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            res = es.search(index=\"arq_ans_ques\", body=body, request_timeout=1000)\n",
    "\n",
    "            for result in res['hits']['hits']:\n",
    "                if str(result['_source']['post_id']) in list_p:\n",
    "                    dict_q_a[topic_id].append(result['_source']['post_id'])\n",
    "\n",
    "            count = 1\n",
    "            for result in res['hits']['hits']:\n",
    "                if str(result['_source']['post_id']) in list_p:\n",
    "                    eval_file.write(topic_id+'\\t'+ '1\\t' +str(result['_source']['post_id'])+'\\t'+str(count)+'\\t'+ str(result['_score'])+'\\t'+ 'mlt_base'+'\\n')\n",
    "                    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ques = {}\n",
    "dict_ans = {}\n",
    "dict_aid_body = {}\n",
    "\n",
    "with jsonlines.open(os.path.join(ques_path)) as reader:\n",
    "        for obj in tqdm(reader):\n",
    "            dict_ques[obj['post_id']] = obj\n",
    "    \n",
    "with jsonlines.open(os.path.join(ans_path)) as reader:\n",
    "        for obj in tqdm(reader):\n",
    "            dict_ans[obj['post_id']] = obj\n",
    "\n",
    "for a_id in tqdm(list(dict_ans.keys())):\n",
    "    ans_body = re.sub('<[^<]+?>', '',  dict_ans[a_id]['body'])\n",
    "    qid = dict_ans[a_id]['parent_id']\n",
    "    ques_body = re.sub('<[^<]+?>', '',  dict_ques[qid]['body'])\n",
    "    ques_title = re.sub('<[^<]+?>', '',  dict_ques[qid]['title'])\n",
    "    dict_aid_body[a_id] = ques_title + '. ' + ques_body #+ '. ' + ans_body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReRanking using fine-tuned HF RoBERTa-Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model name 'shauryr/checkpoint-475000' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-japanese, bert-base-japanese-whole-word-masking, bert-base-japanese-char, bert-base-japanese-char-whole-word-masking, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased, bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum, openai-gpt, transfo-xl-wt103, gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2, ctrl, xlnet-base-cased, xlnet-large-cased, xlm-mlm-en-2048, xlm-mlm-ende-1024, xlm-mlm-enfr-1024, xlm-mlm-enro-1024, xlm-mlm-tlm-xnli15-1024, xlm-mlm-xnli15-1024, xlm-clm-enfr-1024, xlm-clm-ende-1024, xlm-mlm-17-1280, xlm-mlm-100-1280, roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector, distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-cased, distilbert-base-cased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased, distilbert-base-uncased-finetuned-sst-2-english, albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2, camembert-base, umberto-commoncrawl-cased-v1, umberto-wikipedia-uncased-v1, t5-small, t5-base, t5-large, t5-3b, t5-11b, xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german, flaubert-small-cased, flaubert-base-uncased, flaubert-base-cased, flaubert-large-cased, google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert/shauryr/checkpoint-475000/modelcard.json' was a path or url to a model card file named modelcard.json or a directory containing such a file but couldn't find any such file at this path or url.\n",
      "Creating an empty model card.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import *\n",
    "\n",
    "# feat_ext = pipeline(\"feature-extraction\", model=\"shauryr/checkpoint-4000000\", tokenizer='roberta-base', device=0) #our finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f264c712e22f40beaa094702d9fdc135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_emb = []\n",
    "for query in tqdm(queries):\n",
    "    ques_emb.append(np.mean(feat_ext(query)[0], axis=0))\n",
    "\n",
    "del feat_ext\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41abdaf20c8343c586cd03feda4ac53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=98.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dict_q_idx = {}\n",
    "count = 0\n",
    "for topic_id in tqdm(topic_reader._TopicReader__map_topics):\n",
    "    dict_q_idx[topic_id]=0\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_Tuple(tup):  \n",
    "    # reverse = None (Sorts in Ascending order)  \n",
    "    # key is set to sort using second element of  \n",
    "    # sublist lambda has been used  \n",
    "    tup.sort(key = lambda x: x[2])\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_str(tokenizer, body):\n",
    "    encoded = tokenizer.encode(body)[:510]\n",
    "    return tokenizer.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc53018a2c9448cf8e12e69d4898b1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=98.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model name 'shauryr/checkpoint-475000' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-japanese, bert-base-japanese-whole-word-masking, bert-base-japanese-char, bert-base-japanese-char-whole-word-masking, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased, bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum, openai-gpt, transfo-xl-wt103, gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2, ctrl, xlnet-base-cased, xlnet-large-cased, xlm-mlm-en-2048, xlm-mlm-ende-1024, xlm-mlm-enfr-1024, xlm-mlm-enro-1024, xlm-mlm-tlm-xnli15-1024, xlm-mlm-xnli15-1024, xlm-clm-enfr-1024, xlm-clm-ende-1024, xlm-mlm-17-1280, xlm-mlm-100-1280, roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector, distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-cased, distilbert-base-cased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased, distilbert-base-uncased-finetuned-sst-2-english, albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2, camembert-base, umberto-commoncrawl-cased-v1, umberto-wikipedia-uncased-v1, t5-small, t5-base, t5-large, t5-3b, t5-11b, xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german, flaubert-small-cased, flaubert-base-uncased, flaubert-base-cased, flaubert-large-cased, google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert/shauryr/checkpoint-475000/modelcard.json' was a path or url to a model card file named modelcard.json or a directory containing such a file but couldn't find any such file at this path or url.\n",
      "Creating an empty model card.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cb8029bf684d24afbb61eed4ba93d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=146.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2916472\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "count = 0\n",
    "for qid in tqdm(topic_reader._TopicReader__map_topics):\n",
    "    if qid in topic_list:\n",
    "        tup_postid_sim = []\n",
    "        feat_ext = pipeline(\"feature-extraction\", model=\"shauryr/checkpoint-475000\", tokenizer='roberta-base', device=0) #our finetuned model\n",
    "        for post_id in tqdm(dict_q_a[qid]):\n",
    "            try:\n",
    "                feat = feat_ext(dict_aid_body[int(post_id)])[0]\n",
    "                ans_emb = np.mean(feat, axis=0)\n",
    "                del feat\n",
    "                gc.collect()\n",
    "            except:\n",
    "                print(post_id)\n",
    "                continue\n",
    "            result = 1 - spatial.distance.cosine(ques_emb[dict_q_idx[qid]], ans_emb)\n",
    "\n",
    "            if math.isnan(result):\n",
    "                count+=1\n",
    "                print(qid, post_id, count)\n",
    "                continue\n",
    "            tup_postid_sim.append((qid,post_id,result))\n",
    "        try:\n",
    "            del feat_ext\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        except:\n",
    "            print(qid)\n",
    "            continue\n",
    "\n",
    "        result_list.append(Sort_Tuple(tup_postid_sim)[::-1][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf.psu-task1-prim.mlt.bert-auto-both-A.tsv', 'w') as eval_file:\n",
    "    for res in result_list:\n",
    "        count = 1\n",
    "        for tuples in res:\n",
    "            eval_file.write(tuples[0]+'\\t' + str(tuples[1]) +'\\t'+str(count)+'\\t'+ str(tuples[2])+'\\t'+ 'mlt_bert'+'\\n')\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "feat_ext = pipeline(\"feature-extraction\", model=\"/data/szr207/github/transformers/examples/language-modeling/output/checkpoint-3000000\", tokenizer='roberta-base', device=0) #our finetuned model\n",
    "tokenizer =  RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "count = 0\n",
    "for qid in tqdm(list(topic_reader._TopicReader__map_topics.keys())):\n",
    "    tup_postid_sim = []\n",
    "    for post_id in tqdm(dict_q_a[qid]):\n",
    "        try:\n",
    "            feat = feat_ext(reduce_str(tokenizer, dict_aid_body[int(post_id)]))[0]\n",
    "            ans_emb = np.mean(feat, axis=0)\n",
    "        except:\n",
    "            print('CUDA error: an illegal memory access was encountered', post_id)\n",
    "            break\n",
    "        result = 1 - spatial.distance.cosine(ques_emb[dict_q_idx[qid]], ans_emb)\n",
    "        \n",
    "        if math.isnan(result):\n",
    "            count+=1\n",
    "            print(qid, post_id, count)\n",
    "            break\n",
    "        tup_postid_sim.append((qid,post_id,result))\n",
    "#     try:\n",
    "#         del feat_ext\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "#     except:\n",
    "#         print(qid)\n",
    "#         break\n",
    "        \n",
    "    result_list.append(Sort_Tuple(tup_postid_sim)[::-1][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del feat_ext\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf.psu-task1-mlt.bert-auto-both-A.tsv', 'w') as eval_file:\n",
    "    for res in result_list:\n",
    "        count = 1\n",
    "        for tuples in res:\n",
    "#             eval_file.write(tuples[0]+'\\t'+ '1\\t' + str(tuples[1]) +'\\t'+str(count)+'\\t'+ str(tuples[2])+'\\t'+ 'mlt_bert'+'\\n')\n",
    "            eval_file.write(tuples[0]+'\\t' + str(tuples[1]) +'\\t'+str(count)+'\\t'+ str(tuples[2])+'\\t'+ 'mlt_bert'+'\\n')\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging BERT and TF-IDF using RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trectools import TrecRun, TrecEval, fusion\n",
    "\n",
    "runs_path = '/data/szr207/projects/ArqMath/'\n",
    "r1 = TrecRun(os.path.join(runs_path, \"tf.psu-task1-mlt.bert-auto-both-A.tsv\"))\n",
    "r2 = TrecRun(os.path.join(runs_path, \"tf.psu-task1-mlt.base-auto-both-A.tsv\"))\n",
    "\n",
    "# Easy way to create new baselines by fusing existing runs:\n",
    "fused_run = fusion.reciprocal_rank_fusion([r1,r2])\n",
    "\n",
    "# Save run to disk with all its topics\n",
    "fused_run.print_subset(\"tf.psu-task1-rrf.base.bert-auto-both-P.tsv\", topics=fused_run.topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tf.psu-task1-rrf.base.bert-auto-both-P.tsv', header=None , sep=\" \")\n",
    "df = df.drop(columns=1)\n",
    "df.to_csv('psu-task1-rrf.base.bert-auto-both-P.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!java -jar jtreceval-0.0.5-jar-with-dependencies.jar -m ndcg /data/szr207/dataset/ArqMath/Task1/Sample\\ Topics/qrel.V1.0.tsv es.mlt.final.finetune.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul  5 23:43:11 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:18:00.0 Off |                  N/A |\n",
      "| 27%   32C    P8    11W / 250W |   3097MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 49%   58C    P2   233W / 250W |   1438MiB / 11019MiB |     65%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "| 27%   38C    P8    20W / 250W |     11MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:AF:00.0 Off |                  N/A |\n",
      "| 27%   27C    P8     6W / 250W |     11MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0    225899      C   ...a/szr207/conda/envs/faiss/bin/python3.7   709MiB |\n",
      "|    0    337741      C   /data/nud83/anaconda3/envs/py36/bin/python  2377MiB |\n",
      "|    1    225899      C   ...a/szr207/conda/envs/faiss/bin/python3.7  1451MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
