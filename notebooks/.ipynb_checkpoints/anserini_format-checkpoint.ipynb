{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to Anserini format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import jsonlines\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from elasticsearch import Elasticsearch\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import gc\n",
    "import math\n",
    "import torch\n",
    "from transformers import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ques_path = '/data/szr207/dataset/ArqMath/jsons/questions/all.ques.jsonl'\n",
    "ans_path = '/data/szr207/dataset/ArqMath/jsons/answers/all.ans.jsonl'\n",
    "topic_file_path = \"/data/szr207/dataset/ArqMath/Task1/Topics/Topics_V2.0.xml\"\n",
    "# topic_file_path = \"/data/szr207/dataset/ArqMath/Task1/Sample Topics/Task1_Samples_V2.0.xml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1335b07a9f9c4ddc9ac441a8dd090b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7794219b15ea4a64b794363ca4985365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8585321cae4c6682a64c4f2839a5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1435643.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dict_ques = {}\n",
    "dict_ans = {}\n",
    "dict_aid_body = {}\n",
    "list_aq = []\n",
    "\n",
    "with jsonlines.open(os.path.join(ques_path)) as reader:\n",
    "        for obj in tqdm(reader):\n",
    "            dict_ques[obj['post_id']] = obj\n",
    "    \n",
    "with jsonlines.open(os.path.join(ans_path)) as reader:\n",
    "        for obj in tqdm(reader):\n",
    "            dict_ans[obj['post_id']] = obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31db6b993175440fb1a5ab5fadd518c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1435643.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_aq = []\n",
    "\n",
    "for a_id in tqdm(list(dict_ans.keys())):\n",
    "    ans_body = re.sub('<[^<]+?>', '',  dict_ans[a_id]['body'])\n",
    "    qid = dict_ans[a_id]['parent_id']\n",
    "    ques_body = re.sub('<[^<]+?>', '',  dict_ques[qid]['body'])\n",
    "    ques_title = re.sub('<[^<]+?>', '',  dict_ques[qid]['title'])\n",
    "    list_aq.append({'id': a_id, 'contents': ques_title + '. ' + ques_body + '. ' + ans_body})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/szr207/dataset/ArqMath/anserini/arq_anserini_data.json', 'w') as f:\n",
    "    json.dump(list_aq, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b59a680c17d45609bebaa08beccdf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Topic:\n",
    "    \"\"\"\n",
    "    This class shows a topic for task 1. Each topic has an topic_id which is str, a title and question which\n",
    "    is the question body and a list of tags.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, topic_id, title, question, tags):\n",
    "        self.topic_id = topic_id\n",
    "        self.title = title\n",
    "        self.question = question\n",
    "        self.lst_tags = tags\n",
    "\n",
    "\n",
    "class TopicReader:\n",
    "    \"\"\"\n",
    "    This class takes in the topic file path and read all the topics into a map. The key in this map is the topic id\n",
    "    and the values are Topic which has 4 attributes: id, title, question and list of tags for each topic.\n",
    "\n",
    "    To see each topic, use the get_topic method, which takes the topic id and return the topic in Topic object and\n",
    "    you have access to the 4 attributes mentioned above.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, topic_file_path):\n",
    "        self.__map_topics = self.__read_topics(topic_file_path)\n",
    "\n",
    "    def __read_topics(self, topic_file_path):\n",
    "        map_topics = {}\n",
    "        tree = ET.parse(topic_file_path)\n",
    "        root = tree.getroot()\n",
    "        for child in root:\n",
    "            topic_id = child.attrib['number']\n",
    "            title = child[0].text\n",
    "            question = child[1].text\n",
    "            lst_tag = child[2].text.split(\",\")\n",
    "            map_topics[topic_id] = Topic(topic_id, title, question, lst_tag)\n",
    "        return map_topics\n",
    "\n",
    "    def get_topic(self, topic_id):\n",
    "        if topic_id in self.__map_topics:\n",
    "            return self.__map_topics[topic_id]\n",
    "        return None\n",
    "\n",
    "def remove_stop(query):\n",
    "    with open('englishST.txt') as f:\n",
    "        all_stopwords = f.readlines()\n",
    "    # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "    all_stopwords = [x.strip() for x in all_stopwords] \n",
    "    text_tokens = query.split(' ')\n",
    "    query = [word for word in text_tokens if not word in all_stopwords]\n",
    "    query = ' '.join(query)\n",
    "    return query\n",
    "\n",
    "def remove_punct(my_str):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    # To take input from the user\n",
    "    # my_str = input(\"Enter a string: \")\n",
    "\n",
    "    # remove punctuation from the string\n",
    "    no_punct = \"\"\n",
    "    for char in my_str:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "\n",
    "    # display the unpunctuated string\n",
    "    return no_punct\n",
    "\n",
    "es = Elasticsearch(['http://csxindex05:9200/'], verify_certs=True)\n",
    "queries = []\n",
    "#\"In this example, the title and the question body of topic with id A.1 is printed.\"\n",
    "topic_reader = TopicReader(topic_file_path)\n",
    "dict_idx_text = {}\n",
    "\n",
    "with open('all_query_anserini.tsv', 'w') as eval_file:\n",
    "    for topic_id in tqdm(topic_reader._TopicReader__map_topics):\n",
    "        title = re.sub('<[^<]+?>', '', topic_reader.get_topic(topic_id).title)\n",
    "        body = topic_reader.get_topic(topic_id).question\n",
    "        body_pro = re.sub('<[^<]+?>', '', body)\n",
    "        query = title + '. ' + body_pro\n",
    "        eval_file.write(topic_id+'\\t'+query+'\\n')\n",
    "        dict_idx_text[topic_id] = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
